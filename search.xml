<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python读写json使用经验</title>
      <link href="2020/12/11/python-du-xie-json-shi-yong-jing-yan/"/>
      <url>2020/12/11/python-du-xie-json-shi-yong-jing-yan/</url>
      
        <content type="html"><![CDATA[<p>目前在做的工作，对接需要用JSON格式，所以就记录了一些内容。</p><ol><li>爬虫任务，需要把爬下来的数据以json格式转给对方。</li></ol><p>在scrapy框架下，写入json格式的内容，保存.json文件</p><pre><code>class JsonPipeline(object):    def process_item(self, item, spider):        base_dir = &#39;result&#39; + os.sep + item[&#39;keyword&#39;]        if not os.path.isdir(base_dir):            os.makedirs(base_dir)        jsonfile_path = base_dir + os.sep + item[&#39;keyword&#39;] + &#39;.json&#39;        if item:            with codecs.open(jsonfile_path, &#39;a+&#39;) as f:                data = &#123;                &#39;id&#39;: item[&#39;weibo&#39;][&#39;user_id&#39;],                &#39;bid&#39;: item[&#39;weibo&#39;][&#39;bid&#39;],                &#39;screen_name&#39;: item[&#39;weibo&#39;][&#39;screen_name&#39;],                &#39;pics&#39;: item[&#39;weibo&#39;][&#39;pics&#39;]                &#125;                lines = json.dumps(data, ensure_ascii=False)                f.write(lines + &quot;\n&quot;)        return item</code></pre><p>后面传输时，读取json文件，http返回给对方</p><pre><code>json_bigdata = []if keyword == &quot;[&#39;&#39;]&quot;:    file_path = &#39;result/%23&#39; +  str(topic.strip(&quot;#&quot;)) + &#39;%23/%23&#39; +  str(topic.strip(&quot;#&quot;)) + &#39;%23.json&#39;    try:        with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp:            for line in fp.readlines():                json_data = json.loads(line)                json_bigdata.append(json_data)            self.send_response(200)            self.send_header(&#39;Content-Type&#39;, &#39;text/plain; charset=utf-8&#39;)            self.end_headers()            self.wfile.write(str(json_bigdata).encode(&#39;utf-8&#39;))    except:        message_parts.append(&#39;&#39;)        message = &#39;\r\n&#39;.join(message_parts)        self.send_response(200)        self.send_header(&#39;Content-Type&#39;,                         &#39;text/plain; charset=utf-8&#39;)        self.end_headers()        self.wfile.write(message.encode(&#39;utf-8&#39;))</code></pre><ol start="2"><li>更新素材模型时，需要接收同事传来的新增图像数据，是以json格式传来的，我们需要解析处理。</li></ol><p>想到1，我们用过，直接拿过来打开</p><pre><code>import jsonfile_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39;json_bigdata = []try:    with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp:        for line in fp.readlines():            json_data = json.loads(line)            json_bigdata.append(json_data)        print(json_bigdata)        print(len(json_bigdata))except:    print(&#39;open fail&#39;)</code></pre><p>结果：json数据读取出来了，json数据长度为1<br>json数据格式</p><pre><code>&#123;    &quot;code&quot;: 200,    &quot;message&quot;: &quot;OK&quot;,    &quot;data&quot;: [        &#123;            &quot;id&quot;: 19635909,            &quot;pic_url&quot;: &quot;https:\/\/pic.ibaotu.com\/19\/63\/59\/09G888piCrV3.jpg!fw700&quot;,            &quot;tag_names&quot;: &quot;节日海报&quot;        &#125;,        &#123;            &quot;id&quot;: 19640331,            &quot;pic_url&quot;: &quot;https:\/\/pic.ibaotu.com\/19\/64\/03\/31c888piCFMx.jpg!fw700&quot;,            &quot;tag_names&quot;: &quot;海报&quot;        &#125;,        &#123;            &quot;id&quot;: 19643949,            &quot;pic_url&quot;: &quot;https:\/\/pic.ibaotu.com\/01\/99\/30\/693888piC7XF.jpg!fw700&quot;,            &quot;tag_names&quot;: &quot;摄影图&quot;        &#125;    ]&#125;</code></pre><p>接下来我们获取每个key-value的值，来进行处理。所有数据都在一行，它读一行，就把所有数据都读出来了。json_data就是所有数据。我们用print(json_data[“message”])来看看能不能获得想要的值</p><pre><code>file_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39;json_bigdata = []try:    with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp:        for line in fp.readlines():            json_data = json.loads(line)            print(json_data[&quot;message&quot;])            json_bigdata.append(json_data)        # print(json_bigdata)        # print(len(json_bigdata))except:    print(&#39;open fail&#39;)</code></pre><p>运行结果是理想的</p><blockquote><p>OK</p></blockquote><p>接下来把message换成data，看看情况</p><pre><code>file_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39;json_bigdata = []try:    with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp:        for line in fp.readlines():            json_data = json.loads(line)            print(len(json_data[&quot;data&quot;]))            json_bigdata.append(json_data)        # print(json_bigdata)        # print(len(json_bigdata))except:    print(&#39;open fail&#39;)</code></pre><p>结果</p><blockquote><p>778<br>数据一眼看下来，确实很多，应该是获取到了data的值，下面我们需要遍历data来得到每个具体的id，url，类型，把他们下载下来。</p></blockquote><pre><code>file_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39;json_bigdata = []try:    with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp:        for line in fp.readlines():            json_data = json.loads(line)            for i in range(len(json_data[&quot;data&quot;])):                print(json_data[&quot;data&quot;][i])            json_bigdata.append(json_data)        # print(json_bigdata)        # print(len(json_bigdata))except:    print(&#39;open fail&#39;)</code></pre><p>运行结果</p><blockquote><p>{‘id’: 19645448, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/46/15n888piCJF9.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/46/15n888piCJF9.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘摄影图’}<br>{‘id’: 19645623, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/48/24V888piC43a.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/48/24V888piC43a.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘摄影图’}<br>{‘id’: 19645624, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/48/23Z888piCb6y.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/48/23Z888piCb6y.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘摄影图’}<br>{‘id’: 19645634, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/48/40U888piCHSv.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/48/40U888piCHSv.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘摄影图’}<br>{‘id’: 19645663, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/48/73t888piCGVY.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/48/73t888piCGVY.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘节日海报’}<br>{‘id’: 19645667, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/48/71p888piCiK7.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/48/71p888piCiK7.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘节日海报’}<br>{‘id’: 19645679, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/48/67J888piCrMX.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/48/67J888piCrMX.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘节日海报’}<br>{‘id’: 19645719, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/49/28t888piCkgI.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/49/28t888piCkgI.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘节日海报’}<br>{‘id’: 19645730, ‘pic_url’: ‘<a href="https://pic.ibaotu.com/01/99/49/39g888piCxQI.jpg!fw700&#39;">https://pic.ibaotu.com/01/99/49/39g888piCxQI.jpg!fw700&#39;</a>, ‘tag_names’:<br>‘节日海报’}</p></blockquote><p>这个是我们想要的。下面就是得到url，按照分类下载到本地不同的文件夹，以id命名。</p><blockquote><p>print(json_data[“data”][i][‘id’])<br>print(json_data[“data”][i][‘pic_url’])<br>print(json_data[“data”][i][‘tag_names’])</p></blockquote><p>通过url把图像下载下来</p><pre><code>import requestsurl = &quot;https://pic.ibaotu.com/01/99/49/28t888piCkgI.jpg!fw700&quot;try:    r = requests.get(url)    #print(len(r.content))    #if len(r.content) &gt; 20000:    with open(&#39;poster/&#39; + str(file[&#39;id&#39;][i]) + &#39;.jpg&#39;, &#39;wb&#39;) as code:        code.write(r.content)except:    num = num + 1    print(url, num)    with open(&#39;url_false.txt&#39;, &#39;w+&#39;) as f:        f.write(url + &#39;\r\n&#39;)</code></pre><p>接下来就是进行一些图像预处理了。</p>]]></content>
      
      
      <categories>
          
          <category> Python使用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>贝叶斯算法的简单记录</title>
      <link href="2020/12/10/bei-xie-si-suan-fa-de-jian-dan-ji-lu/"/>
      <url>2020/12/10/bei-xie-si-suan-fa-de-jian-dan-ji-lu/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>网络VGG的简单记录</title>
      <link href="2020/12/10/wang-luo-vgg-de-jian-dan-ji-lu/"/>
      <url>2020/12/10/wang-luo-vgg-de-jian-dan-ji-lu/</url>
      
        <content type="html"><![CDATA[<h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p><img src="https://pic.downk.cc/item/5fd1883c3ffa7d37b3e47e27.png"></p><p><img src="https://pic.downk.cc/item/5fd18a733ffa7d37b3e68fc2.png"></p><p>以第一处卷积为例<br>VGG19 卷积层默认的stride是(1, 1)<br>填充方式是same，说明输入的大小和输出的大小一样，都是224<br>卷积核越大，计算量暴增，不利于模型深度的增加，计算性能也会降低。<br>以第一处池化为例<br>MaxPooling2D的padding默认是valid<br>输出大小= (224 - (pool_size=2) + 2 * (p=0)) / (stride=2) + 1 = (224 - 2 + 0)/2 + 1 = 112</p><p> <strong>keras下的vgg19代码</strong></p><pre><code># -*- coding: utf-8 -*-&quot;&quot;&quot;VGG19 model for Keras.# Reference- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)&quot;&quot;&quot;from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionimport osimport warningsfrom ..models import Modelfrom ..layers import Flattenfrom ..layers import Densefrom ..layers import Inputfrom ..layers import Conv2Dfrom ..layers import MaxPooling2Dfrom ..layers import GlobalAveragePooling2Dfrom ..layers import GlobalMaxPooling2Dfrom ..engine.topology import get_source_inputsfrom ..utils import layer_utilsfrom ..utils.data_utils import get_filefrom .. import backend as Kfrom .imagenet_utils import decode_predictionsfrom .imagenet_utils import preprocess_inputfrom .imagenet_utils import _obtain_input_shapeWEIGHTS_PATH = &#39;https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5&#39;WEIGHTS_PATH_NO_TOP = &#39;https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5&#39;def VGG19(include_top=True, weights=&#39;imagenet&#39;,          input_tensor=None, input_shape=None,          pooling=None,          classes=1000):    if not (weights in &#123;&#39;imagenet&#39;, None&#125; or os.path.exists(weights)):        raise ValueError(&#39;The `weights` argument should be either &#39;                         &#39;`None` (random initialization), `imagenet` &#39;                         &#39;(pre-training on ImageNet), &#39;                         &#39;or the path to the weights file to be loaded.&#39;)    if weights == &#39;imagenet&#39; and include_top and classes != 1000:        raise ValueError(&#39;If using `weights` as imagenet with `include_top`&#39;                         &#39; as true, `classes` should be 1000&#39;)    # Determine proper input shape    input_shape = _obtain_input_shape(input_shape,                                      default_size=224,                                      min_size=48,                                      data_format=K.image_data_format(),                                      require_flatten=include_top,                                      weights=weights)    if input_tensor is None:        img_input = Input(shape=input_shape)    else:        if not K.is_keras_tensor(input_tensor):            img_input = Input(tensor=input_tensor, shape=input_shape)        else:            img_input = input_tensor    # Block 1    x = Conv2D(64, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block1_conv1&#39;)(img_input)    x = Conv2D(64, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block1_conv2&#39;)(x)    x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block1_pool&#39;)(x)    # Block 2    x = Conv2D(128, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block2_conv1&#39;)(x)    x = Conv2D(128, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block2_conv2&#39;)(x)    x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block2_pool&#39;)(x)    # Block 3    x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv1&#39;)(x)    x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv2&#39;)(x)    x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv3&#39;)(x)    x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv4&#39;)(x)    x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block3_pool&#39;)(x)    # Block 4    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv1&#39;)(x)    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv2&#39;)(x)    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv3&#39;)(x)    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv4&#39;)(x)    x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block4_pool&#39;)(x)    # Block 5    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv1&#39;)(x)    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv2&#39;)(x)    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv3&#39;)(x)    x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv4&#39;)(x)    x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block5_pool&#39;)(x)    if include_top:        # Classification block        x = Flatten(name=&#39;flatten&#39;)(x)        x = Dense(4096, activation=&#39;relu&#39;, name=&#39;fc1&#39;)(x)        x = Dense(4096, activation=&#39;relu&#39;, name=&#39;fc2&#39;)(x)        x = Dense(classes, activation=&#39;softmax&#39;, name=&#39;predictions&#39;)(x)    else:        if pooling == &#39;avg&#39;:            x = GlobalAveragePooling2D()(x)        elif pooling == &#39;max&#39;:            x = GlobalMaxPooling2D()(x)    # Ensure that the model takes into account    # any potential predecessors of `input_tensor`.    if input_tensor is not None:        inputs = get_source_inputs(input_tensor)    else:        inputs = img_input    # Create model.    model = Model(inputs, x, name=&#39;vgg19&#39;)    # load weights    if weights == &#39;imagenet&#39;:        if include_top:            weights_path = get_file(&#39;vgg19_weights_tf_dim_ordering_tf_kernels.h5&#39;,                                    WEIGHTS_PATH,                                    cache_subdir=&#39;models&#39;,                                    file_hash=&#39;cbe5617147190e668d6c5d5026f83318&#39;)        else:            weights_path = get_file(&#39;vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5&#39;,                                    WEIGHTS_PATH_NO_TOP,                                    cache_subdir=&#39;models&#39;,                                    file_hash=&#39;253f8cb515780f3b799900260a226db6&#39;)        model.load_weights(weights_path)        if K.backend() == &#39;theano&#39;:            layer_utils.convert_all_kernels_in_model(model)        if K.image_data_format() == &#39;channels_first&#39;:            if include_top:                maxpool = model.get_layer(name=&#39;block5_pool&#39;)                shape = maxpool.output_shape[1:]                dense = model.get_layer(name=&#39;fc1&#39;)                layer_utils.convert_dense_weights_data_format(dense, shape, &#39;channels_first&#39;)            if K.backend() == &#39;tensorflow&#39;:                warnings.warn(&#39;You are using the TensorFlow backend, yet you &#39;                              &#39;are using the Theano &#39;                              &#39;image data format convention &#39;                              &#39;(`image_data_format=&quot;channels_first&quot;`). &#39;                              &#39;For best performance, set &#39;                              &#39;`image_data_format=&quot;channels_last&quot;` in &#39;                              &#39;your Keras config &#39;                              &#39;at ~/.keras/keras.json.&#39;)    elif weights is not None:        model.load_weights(weights)    return model</code></pre><p><img src="https://pic.downk.cc/item/5fd198893ffa7d37b3f5554c.png"></p><ol><li>3x3是最小的能够捕获像素八邻域信息的尺寸。</li><li>两个3x3的堆叠卷基层的有限感受野是5x5；三个3x3的堆叠卷基层的感受野是7x7，故可以通过小尺寸卷积层的堆叠替代大尺寸卷积层，并且感受野大小不变。</li><li>多个3x3的卷基层比一个大尺寸filter卷基层有更多的非线性（更多层的非线性函数），使得判决函数更加具有判决性。</li><li>多个3x3的卷积层比一个大尺寸的filter有更少的参数，假设卷基层的输入和输出的特征图大小相同为C，那么三个3x3的卷积层参数个数3x（3x3xCxC）=27C2；一个7x7的卷积层参数为49C2；所以可以把三个3x3的filter看成是一个7x7filter的分解（中间层有非线性的分解, 并且起到隐式正则化的作用。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 经典神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类-自己的数据集-Pytorch</title>
      <link href="2020/12/08/tu-xiang-fen-lei-zi-ji-de-shu-ju-ji-pytorch/"/>
      <url>2020/12/08/tu-xiang-fen-lei-zi-ji-de-shu-ju-ji-pytorch/</url>
      
        <content type="html"><![CDATA[<h3 id="数据集整理划分"><a href="#数据集整理划分" class="headerlink" title="数据集整理划分"></a>数据集整理划分</h3><pre><code>train_transforms = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])train_datasets = datasets.ImageFolder(&#39;dataset/logos_v2&#39;, transform=train_transforms)train_size = int(0.8 * len(train_datasets))test_size = len(train_datasets) - int(0.8 * len(train_datasets))train_dataset, test_dataset = torch.utils.data.random_split(train_datasets, [train_size, test_size])train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)</code></pre><h3 id="训练可视化"><a href="#训练可视化" class="headerlink" title="训练可视化"></a>训练可视化</h3><p>一开始先定义</p><pre><code>from visdom import Visdom# 将窗口类实例化viz = Visdom()viz.line([[0., 0.]], [0], win=&#39;train&#39;, opts=dict(title=&#39;train&#39;, legend=[&#39;train_loss&#39;, &#39;train_acc&#39;]))viz.line([[0., 0.]], [0], win=&#39;test&#39;, opts=dict(title=&#39;test&#39;, legend=[&#39;test_loss&#39;, &#39;test_acc&#39;]))</code></pre><p>后面再记录loss和acc的变化</p><pre><code># 更新窗口图像viz.line([[running_loss / len(train_dataset), train_acc / len(train_dataset)]], [epoch], win=&#39;train&#39;, update=&#39;append&#39;)</code></pre><h3 id="model-train-和model-eval"><a href="#model-train-和model-eval" class="headerlink" title="model.train()和model.eval()"></a>model.train()和model.eval()</h3><p>eval()时，pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。<br>不然的话，一旦test的batch_size过小，很容易就会被BN层导致生成图片颜色失真极大。</p><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><pre><code>import torchfrom torchvision import models, datasets, transformsimport matplotlib.pyplot as pltimport torch.nn as nnimport torch.optim as optimimport torch.nn.functional as Ffrom visdom import Visdom# 将窗口类实例化viz = Visdom()viz.line([[0., 0.]], [0], win=&#39;train&#39;, opts=dict(title=&#39;train&#39;, legend=[&#39;train_loss&#39;, &#39;train_acc&#39;]))viz.line([[0., 0.]], [0], win=&#39;test&#39;, opts=dict(title=&#39;test&#39;, legend=[&#39;test_loss&#39;, &#39;test_acc&#39;]))device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)train_transforms = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])train_datasets = datasets.ImageFolder(&#39;dataset/logos_v2&#39;, transform=train_transforms)train_size = int(0.8 * len(train_datasets))test_size = len(train_datasets) - int(0.8 * len(train_datasets))train_dataset, test_dataset = torch.utils.data.random_split(train_datasets, [train_size, test_size])train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)classes = (&#39;bear&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;chicken&#39;, &#39;coffee&#39;, &#39;dog&#39;, &#39;duck&#39;, &#39;fish&#39;, &#39;flower&#39;, &#39;tree&#39;)net = models.vgg19(pretrained=True)net.to(device)criterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)# 训练网络for epoch in range(10):    net.train()    running_loss = 0.0    train_acc = 0.0    for i, data in enumerate(train_dataloader, 0):        inputs, labels = data        inputs, labels = inputs.to(device), labels.to(device)        optimizer.zero_grad()        outputs = net(inputs)        loss = criterion(outputs, labels)        loss.backward()        optimizer.step()        running_loss += loss.item()        # 经过测试，pred1 = torch.max(outputs, 1)[1]是和_, pred = torch.max(outputs.data, 1) 的pred相等的！！！        #pred1 = torch.max(outputs, 1)[1]        _, pred = torch.max(outputs.data, 1)        train_correct = (pred == labels).sum()        train_acc += train_correct.item()        if i  == len(train_dataloader) - 1:            print(&#39;Training [%d, %5d] loss: %.3f acc: %.3f&#39; % (epoch + 1, i + 1, running_loss / len(train_dataset), train_acc / len(train_dataset)))            # 更新窗口图像            viz.line([[running_loss / len(train_dataset), train_acc / len(train_dataset)]], [epoch], win=&#39;train&#39;, update=&#39;append&#39;)            running_loss = 0.0    # 验证集    net.eval()    eval_loss = 0.0    eval_acc = 0.0    for i, data in enumerate(test_dataloader, 0):        inputs, labels = data        inputs, labels = inputs.to(device), labels.to(device)        outputs = net(inputs)        loss = criterion(outputs, labels)        eval_loss += loss.item()        _, pred = torch.max(outputs.data, 1)        num_correct = (pred == labels).sum()        eval_acc += num_correct.item()        if i  == len(test_dataloader) - 1:            print(&#39;Evaluating [%d, %5d] loss: %.3f acc: %.3f&#39; % (epoch + 1, i + 1, eval_loss / len(test_dataset), eval_acc / len(test_dataset)))            viz.line([[eval_loss / len(test_dataset), eval_acc / len(test_dataset)]], [epoch], win=&#39;test&#39;, update=&#39;append&#39;)            eval_loss = 0.0torch.save(net.state_dict(), &#39;model/logos_v2.pkl&#39;)print(&#39;Finished Training&#39;)# 预测dataiter = iter(test_dataloader)images, labels = dataiter.next()#imshow(torchvision.utils.make_grid(images))print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))images, labels = images.to(device), labels.to(device)#outputs = net(images)net.load_state_dict(torch.load(&#39;model/logos_v2.pkl&#39;))outputs = net(images)_, predicted = torch.max(outputs, 1)print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4)))# 整个数据集预测correct = 0total = 0with torch.no_grad():    for data in test_dataloader:        images, labels = data        images, labels = images.to(device), labels.to(device)        #outputs = net(images)        net.load_state_dict(torch.load(&#39;model/logos_v2.pkl&#39;))        outputs = net(images)        _, predicted = torch.max(outputs.data, 1)        total += labels.size(0)        correct += (predicted == labels).sum().item()print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct / total))</code></pre>]]></content>
      
      
      <categories>
          
          <category> 图像分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习之计算机视觉概念</title>
      <link href="2020/12/08/shen-du-xue-xi-zhi-ji-suan-ji-shi-jue-gai-nian/"/>
      <url>2020/12/08/shen-du-xue-xi-zhi-ji-suan-ji-shi-jue-gai-nian/</url>
      
        <content type="html"><![CDATA[<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>填充</p><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>它们会降低特征平面和卷积层输出的大小<br>池化提供两种不同的功能：一个是减少要处理的数据大小，一个是强制算法不关注图像位置的微小变化</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>ReLU</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类-CIFAR10-Pytorch</title>
      <link href="2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/"/>
      <url>2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/</url>
      
        <content type="html"><![CDATA[<p>想要使用pytorch，就从最基础的图像分类，也是最熟悉的图像分类开始。</p><p>这是官网中文中的代码</p><blockquote><p><a href="http://pytorch123.com/SecondSection/training_a_classifier/">http://pytorch123.com/SecondSection/training_a_classifier/</a></p></blockquote><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>如果直接从源代码下载CIFAR10数据集，本来就只有160M，结果下载一天也没下载好，下载太慢。建议从网上寻找数据集。</p><p>下载完之后，需要修改源码内容。<br>打开我在anaconda下安装torch的虚拟环境，找到torchvision的包，在datasets文件夹下面有个cifar.py</p><blockquote><p>C:\Users\DELL\Anaconda3\envs\torch\Lib\site-packages\torchvision\datasets\cifar.py</p></blockquote><pre><code>class CIFAR10(VisionDataset):    &quot;&quot;&quot;`CIFAR10 &lt;https://www.cs.toronto.edu/~kriz/cifar.html&gt;`_ Dataset.    Args:        root (string): Root directory of dataset where directory            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.        train (bool, optional): If True, creates dataset from training set, otherwise            creates from test set.        transform (callable, optional): A function/transform that takes in an PIL image            and returns a transformed version. E.g, ``transforms.RandomCrop``        target_transform (callable, optional): A function/transform that takes in the            target and transforms it.        download (bool, optional): If true, downloads the dataset from the internet and            puts it in root directory. If dataset is already downloaded, it is not            downloaded again.    &quot;&quot;&quot;    base_folder = &#39;cifar-10-batches-py&#39;    #url = &quot;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&quot;    url = &quot;file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz&quot;    filename = &quot;cifar-10-python.tar.gz&quot;    tgz_md5 = &#39;c58f30108f718f92721af3b95e74349a&#39;    train_list = [        [&#39;data_batch_1&#39;, &#39;c99cafc152244af753f735de768cd75f&#39;],        [&#39;data_batch_2&#39;, &#39;d4bba439e000b95fd0a9bffe97cbabec&#39;],        [&#39;data_batch_3&#39;, &#39;54ebc095f3ab1f0389bbae665268c751&#39;],        [&#39;data_batch_4&#39;, &#39;634d18415352ddfa80567beed471001a&#39;],        [&#39;data_batch_5&#39;, &#39;482c414d41f54cd18b22e5b47cb7c3cb&#39;],    ]</code></pre><p>修改url，把url变成file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz（这个是我下载的cifar10放置的位置）<br>之后运行</p><pre><code>import torchvision as tvimport torchvision.transforms as transformsfrom torchvision.transforms import ToPILImageimport torch.nn as nnimport torch.nn.functional as Fimport torchshow = ToPILImage() # 可以把tensor转成Image，方便可视化transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])trainset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)testset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)(data, label) = trainset[100]print(classes[label])print(len(trainset))print(len(testset))</code></pre><pre><code>输出：Files already downloaded and verifiedFiles already downloaded and verifiedship5000010000</code></pre><h3 id="创建网络"><a href="#创建网络" class="headerlink" title="创建网络"></a>创建网络</h3><pre><code>class Net_my(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1  = nn.Conv2d(3, 6, 5)        self.conv2  = nn.Conv2d(6, 16, 5)        self.fc1    = nn.Linear(16*5*5, 120)        self.fc2    = nn.Linear(120, 84)        self.fc3    = nn.Linear(84, 10)    def forward(self, x):        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))        x = F.max_pool2d(F.relu(self.conv2(x)), 2)        x = x.view(x.size()[0], -1)        x = F.relu(self.fc1(x))        x = F.relu(self.fc2(x))        x = self.fc3(x)        return x</code></pre><p>本来报错：</p><blockquote><p>class Net_my(nn.modules):<br>TypeError: module.<strong>init</strong>() takes at most 2 arguments (3 given)</p></blockquote><p>nn.modules -&gt; nn.Module就ok了。</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>报错</p><blockquote><p>BrokenPipeError: [Errno 32] Broken pipe</p></blockquote><p> 好像是win10的多线程导致的，需要避免windows使用多线程。把torch.utils.data.DataLoader()函数时的 num_workers 参数改成0。</p><blockquote><p>RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same</p></blockquote><p>要么都是cpu，要么都是gpu，需要统一</p><blockquote><p>net.cuda()<br>device = torch.device(“cuda:0” if torch.cuda.is_available() else “cpu”)<br>#网络和输入的数据都需要转成gpu或者cpu。</p></blockquote><p>可以训练</p><pre><code># net = Net()# net.cuda()# from torch import optim# criterion = nn.CrossEntropyLoss()# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)# device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)## torch.set_num_threads(8)# for epoch in range(10):#     running_loss = 0.0#     total = 0#     correct = 0#     for i, data in enumerate(trainloader, 0):#         inputs, labels = data#         inputs, labels = inputs.to(device),labels.to(device)##         optimizer.zero_grad()#         outputs = net(inputs)#         loss = criterion(outputs, labels)#         loss.backward()##         optimizer.step()##         running_loss += loss.item()##         if i % 2000 == 1999:#             print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch+1, i+1, running_loss / 2000))#             running_loss = 0.0#             _, predicted = torch.max(outputs, 1)#             total += labels.size(0)#             correct += (predicted == labels).sum().item()#             print(&#39;accuracy of the network on the %d train images: %.3f %%&#39; % (total, 100.0 * correct / total))#             total = 0#             correct = 0## print(&#39;Finished Training&#39;)</code></pre><h3 id="使用预训练模型来图像分类"><a href="#使用预训练模型来图像分类" class="headerlink" title="使用预训练模型来图像分类"></a>使用预训练模型来图像分类</h3><pre><code>import torchvision as tvimport torchvision.transforms as transformsfrom torchvision.transforms import ToPILImageimport torch.nn as nnimport torch.nn.functional as Fimport torchfrom torchvision import modelsfrom PIL import Imagealexnet = models.alexnet(pretrained=True)print(alexnet)img = Image.open(&#39;1.jpg&#39;)transform = transforms.Compose([            #[1] transforms.Resize(256),                    #[2] transforms.CenterCrop(224),                #[3] transforms.ToTensor(),                     #[4] transforms.Normalize(                      #[5] mean=[0.485, 0.456, 0.406],                #[6] std=[0.229, 0.224, 0.225]                  #[7] )])img_t = transform(img)batch_t = torch.unsqueeze(img_t, 0)alexnet.eval()out = alexnet(batch_t)with open(&#39;imagenet_classes.txt&#39;) as f:    classes = [line.strip() for line in f.readlines()]_, indices = torch.sort(out, descending=True)percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100[print(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]</code></pre><pre><code>输出655: &#39;miniskirt, mini&#39;, 10.492936134338379765: &#39;rocking chair, rocker&#39;, 4.194277286529541545: &#39;electric fan, blower&#39;, 4.150004863739014411: &#39;apron&#39;, 2.946284532546997589: &#39;hand blower, blow dryer, blow drier, hair dryer, hair drier&#39;, 2.749168872833252</code></pre><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><pre><code>import torchimport torchvisionimport torchvision.transforms as transformsdevice = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)# 使用torchvision加载并且归一化CIFAR10的训练和测试数据集transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)testset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)# 显示一批图像import matplotlib.pyplot as pltimport numpy as npdef imshow(img):    img = img / 2 + 0.5    npimg = img.numpy()    plt.imshow(np.transpose(npimg, (1, 2, 0)))    plt.show()dataiter = iter(trainloader)images, labels = dataiter.next()#imshow(torchvision.utils.make_grid(images))print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))# 定义一个卷积神经网络import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1 = nn.Conv2d(3, 6, 5)        self.pool = nn.MaxPool2d(2, 2)        self.conv2 = nn.Conv2d(6, 16, 5)        self.fc1 = nn.Linear(16 * 5 * 5, 120)        self.fc2 = nn.Linear(120, 84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        x = self.pool(F.relu(self.conv1(x)))        x = self.pool(F.relu(self.conv2(x)))        x = x.view(-1, 16 * 5 * 5)        x = F.relu(self.fc1(x))        x = F.relu(self.fc2(x))        x = self.fc3(x)        return xnet = Net()net.to(device)# 定义一个损失函数和优化器 让我们使用分类交叉熵Cross-Entropy 作损失函数，动量SGD做优化器。import torch.optim as optimcriterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)# 训练网络for epoch in range(5):    running_loss = 0.0    for i, data in enumerate(trainloader, 0):        inputs, labels = data        inputs, labels = inputs.to(device), labels.to(device)        optimizer.zero_grad()        outputs = net(inputs)        loss = criterion(outputs, labels)        loss.backward()        optimizer.step()        running_loss += loss.item()        if i % 1562 == 1555:            print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i + 1, running_loss / 2000))            running_loss = 0.0torch.save(net.state_dict(), &#39;model/cifar10.pkl&#39;)print(&#39;Finished Training&#39;)# 预测dataiter = iter(testloader)images, labels = dataiter.next()#imshow(torchvision.utils.make_grid(images))print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))images, labels = images.to(device), labels.to(device)#outputs = net(images)net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;))outputs = net(images)_, predicted = torch.max(outputs, 1)print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4)))# 整个数据集预测correct = 0total = 0with torch.no_grad():    for data in testloader:        images, labels = data        images, labels = images.to(device), labels.to(device)        #outputs = net(images)        net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;))        outputs = net(images)        _, predicted = torch.max(outputs.data, 1)        total += labels.size(0)        correct += (predicted == labels).sum().item()print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct / total))# 最后测试准确率在53%左右</code></pre>]]></content>
      
      
      <categories>
          
          <category> 图像分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跑通图像压缩算法SReC</title>
      <link href="2020/12/03/srec/"/>
      <url>2020/12/03/srec/</url>
      
        <content type="html"><![CDATA[<pre><code>环境：win10源码位置：https://github.com/caoscott/SReC</code></pre><h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h3><p>git clone <a href="mailto:&#x67;&#x69;&#116;&#64;&#103;&#x69;&#116;&#x68;&#117;&#98;&#46;&#x63;&#111;&#109;">&#x67;&#x69;&#116;&#64;&#103;&#x69;&#116;&#x68;&#117;&#98;&#46;&#x63;&#111;&#109;</a>:caoscott/SReC.git</p><h3 id="搭建环境，使用的是没有nvidia-docker的方法"><a href="#搭建环境，使用的是没有nvidia-docker的方法" class="headerlink" title="搭建环境，使用的是没有nvidia-docker的方法"></a>搭建环境，使用的是没有nvidia-docker的方法</h3><p>我是已经装了torch1.5.0 + torchvision0.6.0 + gpu的环境，接下来</p><ol><li><p>pip install -r requirements.txt</p></li><li><p>安装gcc，参考的是这个大佬的文章<a href="https://blog.csdn.net/qilimi1053620912/article/details/88573017">https://blog.csdn.net/qilimi1053620912/article/details/88573017</a><br>在windows10上安装gcc。</p></li><li><p>运行COMPILE_CUDA=force python3 setup.py install，报错</p><blockquote><p>error: command ‘C:\Program Files (x86)\Microsoft Visual Studio\2017\Communit<br>y\VC\Tools\MSVC\14.16.27023\bin\HostX86\x64\cl.exe’ failed with exit sta<br>tus 2</p></blockquote></li></ol><p>搞不定啊</p>]]></content>
      
      
      <categories>
          
          <category> 跑过的算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像压缩 </tag>
            
            <tag> 图像处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>supervisor + scrapy + python</title>
      <link href="2020/11/26/supervisor-scrapy-python/"/>
      <url>2020/11/26/supervisor-scrapy-python/</url>
      
        <content type="html"><![CDATA[<p>在ubuntu16.04下，首先爬取新浪微博的话题和关键词，然后会返回爬到的微博用户id，bid，和图像url。<br>之后再把这些图像送到深度学习所做的图像侵权检测系统，判断是否侵权我们的素材，返回相关的信息。</p><p>1.图像侵权检测</p><p>2.python 开启http服务</p><p>3.scrapy 爬取新浪微博</p><p>4.supervisor 进程管理</p><p>其实123慢慢调好了，这周调的最多的是怎么把1234放在一起，碰到了相当多的问题。</p><h3 id="开启supervisor-执行的命令可以是虚拟环境的命令，需要加上路径"><a href="#开启supervisor-执行的命令可以是虚拟环境的命令，需要加上路径" class="headerlink" title="开启supervisor 执行的命令可以是虚拟环境的命令，需要加上路径"></a>开启supervisor 执行的命令可以是虚拟环境的命令，需要加上路径</h3><p>比如</p><blockquote><p>[program:ibaotu-image-match]<br>command=<strong>/usr/local/data/anaconda3/envs/snakes/bin/python</strong> /usr/local/data/www/weibo_search_master/http_server_GET.py<br>directory=/usr/local/data/www/weibo_search_master<br>autostart=true<br>autorestart=true<br>stdout_logfile=/usr/local/data/www/log/out.log<br>stderr_logfile=/usr/local/data/www/log/err.log</p></blockquote><p>执行命令的时候就知道是执行哪里的python了</p><p>还可以web查看管理supervisor</p><blockquote><p>[inet_http_server] ; inet (TCP) server disabled by default<br>port=*:9001 ; (ip_address:port specifier, *:port for all iface)<br>;username=admin ; (default is no username (open server))<br>;password=admin ; (default is no password (open server))</p></blockquote><h3 id="supervisor命令"><a href="#supervisor命令" class="headerlink" title="supervisor命令"></a>supervisor命令</h3><p>查看状态<br>supervisorctl status<br>更新<br>supervisorctl update<br>重置<br>supervisorctl reload<br>结束<br>supervisorctl stop all<br>开始<br>supervisorctl start all<br>更新配置<br>supervisord -c /etc/supervisord/supervisord.conf</p><h3 id="遇到的报错"><a href="#遇到的报错" class="headerlink" title="遇到的报错"></a>遇到的报错</h3><blockquote><p>unix:///var/run/supervisor.sock no such file</p></blockquote><p>1.sudo touch /var/run/supervisor.sock</p><p>2.sudo chmod 777 /var/run/supervisor.sock</p><p>3.sudo service supervisor restart</p><blockquote><p>unix:///var/run/supervisor/supervisor.sock refused connection</p></blockquote><p>supervisord -c /etc/supervisord/supervisord.conf<br>启动supervisord并使用配置</p><blockquote><p>The ‘supervisor==3.2.0’ distribution was not found and is required by the application</p></blockquote><p>如果默认的python是python2,应该不会报错。如果是python3，就要修改<br>和terminator一样也是python版本引起的，编辑/usr/bin/supervisord将#!/usr/bin/python修改为#!/usr/bin/python2即可<br>貌似启动supervisor 只能用python2</p><blockquote><p>supervisord不能正常地话，查看它的log</p></blockquote><p>supervisorctl tail ibaotu-image-match stderr</p><blockquote><p>supervisorctl 启动起来，一直在报错重启， OSError: [Errno 98] Address already in use</p></blockquote><p>1.<br>netstat -tunlp<br>kill -9 6153<br>这个是每次都要这样，有点烦<br>2.<br>find / -name supervisor.sock<br>unlink /name/supervisor.sock</p><blockquote><p>root@ibaotu-algo:/usr/bin# scrapy<br>Traceback (most recent call last):<br>  File “/usr/local/bin/scrapy”, line 7, in <module><br>    from scrapy.cmdline import execute<br>  File “/usr/local/lib/python3.5/dist-packages/scrapy/<strong>init</strong>.py”, line 12, in <module><br>    from scrapy.spiders import Spider<br>  File “/usr/local/lib/python3.5/dist-packages/scrapy/spiders/<strong>init</strong>.py”, line 22<br>    name: Optional[str] = None<br>        ^<br>SyntaxError: invalid syntax</p></blockquote><p>在虚拟环境是好的，但是放在一起跑就出问题了。我研究了好久，才发现还是命令路径的问题。<br>在终端输入scrapy，虚拟环境是ok的，在普通的就报错。两个scrapy版本是一样的，<br>只不过虚拟环境的python是3.6.5，普通的python是3.5.2，不知道是不是和这个有关。<br>把scrapy改成/usr/local/data/anaconda3/envs/snakes/bin/scrapy</p><blockquote><p>scrapy是命令行，怎么在代码里面添加？</p></blockquote><pre><code>#cmdline.execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;search&quot;, &quot;-a&quot;, &quot;start_date=%s&quot;%(start_date), &quot;-a&quot;, &quot;end_date=%s&quot;%(end_date), &quot;-a&quot;, &quot;keyword_list=%s&quot;%(keyword)])cmd = &quot;/usr/local/data/anaconda3/envs/snakes/bin/scrapy crawl search -a &quot; + &quot;start_date=%s&quot;%(start_date) + &quot; -a &quot; + &quot;end_date=%s&quot;%(end_date) + &quot; -a &quot; + &quot;keyword_list=%s&quot;%(keyword)os.system(cmd)</code></pre><blockquote><p>开启的http服务，客户请求爬虫，怎么把数据返回？</p></blockquote><p>一开始的想法是能不能搞个全局变量。怎么搞也搞不过去，<br>python跨文件的全局变量，后面知道scrapy是新开的进程，数据根本到不了。<br>后面把数据存到csv或者json文件，爬完再读取，再返回。</p><blockquote><p>no module named …</p></blockquote><p>因为路径的问题，也搞了好久，明明都添加了，还是报错，sys.path.append()<br>最后因为没有使用到全局变量，这个报错也就不了了之了。</p><blockquote><p>遍历字典，写入csv，一个数据固定的写入一行</p></blockquote><p>writer.writerow([item[‘weibo’][key] for key in item[‘weibo’].keys() if key == ‘id’ or key == ‘bid’ or key == ‘pics’])</p><blockquote><p>是csv转成json，还是直接爬取pipeline到json</p></blockquote><p>我选择了后者，爬取了json格式的文件下来，包括id，bid，picurl组成的json格式的数据。<br>一开始json格式还写不进去，应该是格式问题，我弄了data格式，之后ok了。</p><pre><code>with codecs.open(jsonfile_path, &#39;a+&#39;) as f:    data = &#123;    &#39;id&#39;: item[&#39;weibo&#39;][&#39;user_id&#39;],    &#39;bid&#39;: item[&#39;weibo&#39;][&#39;bid&#39;],    &#39;screen_name&#39;: item[&#39;weibo&#39;][&#39;screen_name&#39;],    &#39;pics&#39;: item[&#39;weibo&#39;][&#39;pics&#39;]    &#125;    lines = json.dumps(data, ensure_ascii=False)    f.write(lines + &quot;\n&quot;)</code></pre><blockquote><p>然后也出现supervisor一直重启的问题</p></blockquote><p>因为配置中restart:默认为true，然后一直有htpp进程开着，报错OSError: [Errno 98] Address already in use；还有个原因就是原来的程序不是死循环，一会运行结束，又重启了。</p><h3 id="最后这个1234基本就能愉快地在一起玩耍了。"><a href="#最后这个1234基本就能愉快地在一起玩耍了。" class="headerlink" title="最后这个1234基本就能愉快地在一起玩耍了。"></a>最后这个1234基本就能愉快地在一起玩耍了。</h3>]]></content>
      
      
      <categories>
          
          <category> 项目经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conda的使用</title>
      <link href="2020/11/23/conda-de-shi-yong/"/>
      <url>2020/11/23/conda-de-shi-yong/</url>
      
        <content type="html"><![CDATA[<h3 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h3><p>首先需要安装anaconda，在不同的电脑上下载使用很多次了，还是挺方便的。正好开通了博客，就记录下conda的使用。</p><h3 id="conda-创建虚拟环境"><a href="#conda-创建虚拟环境" class="headerlink" title="conda 创建虚拟环境"></a>conda 创建虚拟环境</h3><p>anaconda安装成功之后，如果不成功，网上很多安装的博客可以查看。应该有conda命令了。</p><p><code>conda -V</code></p><p>返回<code>conda 4.7.12</code></p><h5 id="1-创建虚拟环境"><a href="#1-创建虚拟环境" class="headerlink" title="1.创建虚拟环境"></a>1.创建虚拟环境</h5><p>命令：<br><code>conda create --name pytorch python=3.6.5</code></p><p>安装总是失败</p><pre><code>Collecting package metadata (current_repodata.json): ...working... doneSolving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.Collecting package metadata (repodata.json): ...working...</code></pre><p>我添加了conda换源，可是还是不行</p><pre><code>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes</code></pre><p>修改命令<br><code>conda create --name pytorch python=3.6</code></p><pre><code>$ conda create -n tensorflow python=3.6.5Collecting package metadata (repodata.json): doneSolving environment: done==&gt; WARNING: A newer version of conda exists. &lt;==  current version: 4.8.3  latest version: 4.9.2Please update conda by running    $ conda update -n base -c defaults conda## Package Plan ##  environment location: C:\Users\DELL\Anaconda3\envs\tensorflow  added / updated specs:    - python=3.6.5The following packages will be downloaded:    package                    |            build    ---------------------------|-----------------    certifi-2020.11.8          |   py36haa95532_0         151 KB    pip-20.2.4                 |   py36haa95532_0         2.1 MB    python-3.6.5               |       h0c2934d_0        21.6 MB    setuptools-50.3.1          |   py36haa95532_1         939 KB    vc-14.1                    |       h0510ff6_4           6 KB    vs2015_runtime-14.16.27012 |       hf0eaf9b_3         2.4 MB    wincertstore-0.2           |   py36h7fe50ca_0          13 KB    ------------------------------------------------------------                                           Total:        27.2 MBThe following NEW packages will be INSTALLED:done## To activate this environment, use##     $ conda activate tensorflow## To deactivate an active environment, use##     $ conda deactivate</code></pre><p>2.安装成功之后，可以查看确认下<code>conda env list</code></p><h3 id="conda-进入虚拟环境"><a href="#conda-进入虚拟环境" class="headerlink" title="conda 进入虚拟环境"></a>conda 进入虚拟环境</h3><p>conda activate tensorflow<br>或者<br>source activate tensorflow</p><h3 id="conda-退出虚拟环境"><a href="#conda-退出虚拟环境" class="headerlink" title="conda 退出虚拟环境"></a>conda 退出虚拟环境</h3><p>conda deactivate<br>或者试试source deactivate<br>没有退出，就多输入几次命令</p><h3 id="conda-添加镜像"><a href="#conda-添加镜像" class="headerlink" title="conda 添加镜像"></a>conda 添加镜像</h3><p>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/</a><br>#显示安装的镜像<br>conda config –set show_channel_urls yes<br>#已添加的channel在哪里查看<br>.condarc</p><h3 id="conda-删除虚拟环境"><a href="#conda-删除虚拟环境" class="headerlink" title="conda 删除虚拟环境"></a>conda 删除虚拟环境</h3><p>conda remove -n tensorflow –all</p><pre><code>conda remove -n tensorflow --allRemove all packages in environment C:\Users\DELL\Anaconda3\envs\tensorflow:## Package Plan ##  environment location: C:\Users\DELL\Anaconda3\envs\tensorflowThe following packages will be REMOVED:  certifi-2020.11.8-py36haa95532_0  pip-20.2.4-py36haa95532_0  python-3.6.5-h0c2934d_0  setuptools-50.3.1-py36haa95532_1  vc-14.1-h0510ff6_4  vs2015_runtime-14.16.27012-hf0eaf9b_3  wheel-0.35.1-pyhd3eb1b0_0  wincertstore-0.2-py36h7fe50ca_0Proceed ([y]/n)? yPreparing transaction: doneVerifying transaction: doneExecuting transaction: done</code></pre><p>我正常用的就是这些命令，记录一下。</p>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> anaconda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开发工具</title>
      <link href="2020/11/19/kai-fa-gong-ju/"/>
      <url>2020/11/19/kai-fa-gong-ju/</url>
      
        <content type="html"><![CDATA[<h3 id="这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。"><a href="#这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。" class="headerlink" title="这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。"></a>这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。</h3><h2 id="编辑器：Atom-（使用体验超级好）"><a href="#编辑器：Atom-（使用体验超级好）" class="headerlink" title="编辑器：Atom （使用体验超级好）"></a>编辑器：Atom （使用体验超级好）</h2><h4 id="Packages："><a href="#Packages：" class="headerlink" title="Packages："></a>Packages：</h4><p>1.Hydropen<br>2.activate_power_mode<br>3.atom_python_run<br>4.atom_terminal<br>5.autocomplete-python<br>6.hyperclick<br>7.ide-python<br><strong>8.kite # 特别好用，使用有惊喜</strong><br>9.minimap<br>10.python-tools<br>11.run-in-terminal<br>其他很多包全是core packages，不进行列举。</p><h2 id="远程连接传输工具：Xshell-Winscp-Putty"><a href="#远程连接传输工具：Xshell-Winscp-Putty" class="headerlink" title="远程连接传输工具：Xshell Winscp Putty"></a>远程连接传输工具：Xshell Winscp Putty</h2><h2 id="Coding：Pycharm-Anaconda-Visual-Studio-Source-Insight"><a href="#Coding：Pycharm-Anaconda-Visual-Studio-Source-Insight" class="headerlink" title="Coding：Pycharm Anaconda Visual-Studio Source-Insight"></a>Coding：Pycharm Anaconda Visual-Studio Source-Insight</h2><h2 id="数据库：HeidiSQL"><a href="#数据库：HeidiSQL" class="headerlink" title="数据库：HeidiSQL"></a>数据库：HeidiSQL</h2><h2 id="查看神经网络的结构：Netron"><a href="#查看神经网络的结构：Netron" class="headerlink" title="查看神经网络的结构：Netron"></a>查看神经网络的结构：Netron</h2><h2 id="Cuda：v10-0"><a href="#Cuda：v10-0" class="headerlink" title="Cuda：v10.0"></a>Cuda：v10.0</h2><h2 id="Cudnn：v7-6-5"><a href="#Cudnn：v7-6-5" class="headerlink" title="Cudnn：v7.6.5"></a>Cudnn：v7.6.5</h2><h2 id="查看windows文件：listary"><a href="#查看windows文件：listary" class="headerlink" title="查看windows文件：listary"></a>查看windows文件：listary</h2>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>about</title>
      <link href="about/index.html"/>
      <url>about/index.html</url>
      
        <content type="html"><![CDATA[<p>我是小骨子，欢迎您</p>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>contact</title>
      <link href="contact/index.html"/>
      <url>contact/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>categories</title>
      <link href="categories/index.html"/>
      <url>categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="tags/index.html"/>
      <url>tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
