<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>图像分类-自己的数据集-Pytorch</title>
      <link href="2020/12/08/tu-xiang-fen-lei-zi-ji-de-shu-ju-ji-pytorch/"/>
      <url>2020/12/08/tu-xiang-fen-lei-zi-ji-de-shu-ju-ji-pytorch/</url>
      
        <content type="html"><![CDATA[<h3 id="数据集整理划分"><a href="#数据集整理划分" class="headerlink" title="数据集整理划分"></a>数据集整理划分</h3><pre><code>train_transforms = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])train_datasets = datasets.ImageFolder(&#39;dataset/logos_v2&#39;, transform=train_transforms)train_size = int(0.8 * len(train_datasets))test_size = len(train_datasets) - int(0.8 * len(train_datasets))train_dataset, test_dataset = torch.utils.data.random_split(train_datasets, [train_size, test_size])train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)</code></pre><h3 id="训练可视化"><a href="#训练可视化" class="headerlink" title="训练可视化"></a>训练可视化</h3><p>一开始先定义</p><pre><code>from visdom import Visdom# 将窗口类实例化viz = Visdom()viz.line([[0., 0.]], [0], win=&#39;train&#39;, opts=dict(title=&#39;train&#39;, legend=[&#39;train_loss&#39;, &#39;train_acc&#39;]))viz.line([[0., 0.]], [0], win=&#39;test&#39;, opts=dict(title=&#39;test&#39;, legend=[&#39;test_loss&#39;, &#39;test_acc&#39;]))</code></pre><p>后面再记录loss和acc的变化</p><pre><code># 更新窗口图像viz.line([[running_loss / len(train_dataset), train_acc / len(train_dataset)]], [epoch], win=&#39;train&#39;, update=&#39;append&#39;)</code></pre><h3 id="model-train-和model-eval"><a href="#model-train-和model-eval" class="headerlink" title="model.train()和model.eval()"></a>model.train()和model.eval()</h3><p>eval()时，pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。<br>不然的话，一旦test的batch_size过小，很容易就会被BN层导致生成图片颜色失真极大。</p><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><pre><code>import torchfrom torchvision import models, datasets, transformsimport matplotlib.pyplot as pltimport torch.nn as nnimport torch.optim as optimimport torch.nn.functional as Ffrom visdom import Visdom# 将窗口类实例化viz = Visdom()viz.line([[0., 0.]], [0], win=&#39;train&#39;, opts=dict(title=&#39;train&#39;, legend=[&#39;train_loss&#39;, &#39;train_acc&#39;]))viz.line([[0., 0.]], [0], win=&#39;test&#39;, opts=dict(title=&#39;test&#39;, legend=[&#39;test_loss&#39;, &#39;test_acc&#39;]))device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)train_transforms = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])train_datasets = datasets.ImageFolder(&#39;dataset/logos_v2&#39;, transform=train_transforms)train_size = int(0.8 * len(train_datasets))test_size = len(train_datasets) - int(0.8 * len(train_datasets))train_dataset, test_dataset = torch.utils.data.random_split(train_datasets, [train_size, test_size])train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)classes = (&#39;bear&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;chicken&#39;, &#39;coffee&#39;, &#39;dog&#39;, &#39;duck&#39;, &#39;fish&#39;, &#39;flower&#39;, &#39;tree&#39;)net = models.vgg19(pretrained=True)net.to(device)criterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)# 训练网络for epoch in range(10):    net.train()    running_loss = 0.0    train_acc = 0.0    for i, data in enumerate(train_dataloader, 0):        inputs, labels = data        inputs, labels = inputs.to(device), labels.to(device)        optimizer.zero_grad()        outputs = net(inputs)        loss = criterion(outputs, labels)        loss.backward()        optimizer.step()        running_loss += loss.item()        # 经过测试，pred1 = torch.max(outputs, 1)[1]是和_, pred = torch.max(outputs.data, 1) 的pred相等的！！！        #pred1 = torch.max(outputs, 1)[1]        _, pred = torch.max(outputs.data, 1)        train_correct = (pred == labels).sum()        train_acc += train_correct.item()        if i  == len(train_dataloader) - 1:            print(&#39;Training [%d, %5d] loss: %.3f acc: %.3f&#39; % (epoch + 1, i + 1, running_loss / len(train_dataset), train_acc / len(train_dataset)))            # 更新窗口图像            viz.line([[running_loss / len(train_dataset), train_acc / len(train_dataset)]], [epoch], win=&#39;train&#39;, update=&#39;append&#39;)            running_loss = 0.0    # 验证集    net.eval()    eval_loss = 0.0    eval_acc = 0.0    for i, data in enumerate(test_dataloader, 0):        inputs, labels = data        inputs, labels = inputs.to(device), labels.to(device)        outputs = net(inputs)        loss = criterion(outputs, labels)        eval_loss += loss.item()        _, pred = torch.max(outputs.data, 1)        num_correct = (pred == labels).sum()        eval_acc += num_correct.item()        if i  == len(test_dataloader) - 1:            print(&#39;Evaluating [%d, %5d] loss: %.3f acc: %.3f&#39; % (epoch + 1, i + 1, eval_loss / len(test_dataset), eval_acc / len(test_dataset)))            viz.line([[eval_loss / len(test_dataset), eval_acc / len(test_dataset)]], [epoch], win=&#39;test&#39;, update=&#39;append&#39;)            eval_loss = 0.0torch.save(net.state_dict(), &#39;model/logos_v2.pkl&#39;)print(&#39;Finished Training&#39;)# 预测dataiter = iter(test_dataloader)images, labels = dataiter.next()#imshow(torchvision.utils.make_grid(images))print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))images, labels = images.to(device), labels.to(device)#outputs = net(images)net.load_state_dict(torch.load(&#39;model/logos_v2.pkl&#39;))outputs = net(images)_, predicted = torch.max(outputs, 1)print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4)))# 整个数据集预测correct = 0total = 0with torch.no_grad():    for data in test_dataloader:        images, labels = data        images, labels = images.to(device), labels.to(device)        #outputs = net(images)        net.load_state_dict(torch.load(&#39;model/logos_v2.pkl&#39;))        outputs = net(images)        _, predicted = torch.max(outputs.data, 1)        total += labels.size(0)        correct += (predicted == labels).sum().item()print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct / total))</code></pre>]]></content>
      
      
      <categories>
          
          <category> 图像分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习之计算机视觉概念</title>
      <link href="2020/12/08/shen-du-xue-xi-zhi-ji-suan-ji-shi-jue-gai-nian/"/>
      <url>2020/12/08/shen-du-xue-xi-zhi-ji-suan-ji-shi-jue-gai-nian/</url>
      
        <content type="html"><![CDATA[<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>填充</p><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>它们会降低特征平面和卷积层输出的大小<br>池化提供两种不同的功能：一个是减少要处理的数据大小，一个是强制算法不关注图像位置的微小变化</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>ReLU</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类-CIFAR10-Pytorch</title>
      <link href="2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/"/>
      <url>2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/</url>
      
        <content type="html"><![CDATA[<p>想要使用pytorch，就从最基础的图像分类，也是最熟悉的图像分类开始。</p><p>这是官网中文中的代码</p><blockquote><p><a href="http://pytorch123.com/SecondSection/training_a_classifier/">http://pytorch123.com/SecondSection/training_a_classifier/</a></p></blockquote><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>如果直接从源代码下载CIFAR10数据集，本来就只有160M，结果下载一天也没下载好，下载太慢。建议从网上寻找数据集。</p><p>下载完之后，需要修改源码内容。<br>打开我在anaconda下安装torch的虚拟环境，找到torchvision的包，在datasets文件夹下面有个cifar.py</p><blockquote><p>C:\Users\DELL\Anaconda3\envs\torch\Lib\site-packages\torchvision\datasets\cifar.py</p></blockquote><pre><code>class CIFAR10(VisionDataset):    &quot;&quot;&quot;`CIFAR10 &lt;https://www.cs.toronto.edu/~kriz/cifar.html&gt;`_ Dataset.    Args:        root (string): Root directory of dataset where directory            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.        train (bool, optional): If True, creates dataset from training set, otherwise            creates from test set.        transform (callable, optional): A function/transform that takes in an PIL image            and returns a transformed version. E.g, ``transforms.RandomCrop``        target_transform (callable, optional): A function/transform that takes in the            target and transforms it.        download (bool, optional): If true, downloads the dataset from the internet and            puts it in root directory. If dataset is already downloaded, it is not            downloaded again.    &quot;&quot;&quot;    base_folder = &#39;cifar-10-batches-py&#39;    #url = &quot;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&quot;    url = &quot;file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz&quot;    filename = &quot;cifar-10-python.tar.gz&quot;    tgz_md5 = &#39;c58f30108f718f92721af3b95e74349a&#39;    train_list = [        [&#39;data_batch_1&#39;, &#39;c99cafc152244af753f735de768cd75f&#39;],        [&#39;data_batch_2&#39;, &#39;d4bba439e000b95fd0a9bffe97cbabec&#39;],        [&#39;data_batch_3&#39;, &#39;54ebc095f3ab1f0389bbae665268c751&#39;],        [&#39;data_batch_4&#39;, &#39;634d18415352ddfa80567beed471001a&#39;],        [&#39;data_batch_5&#39;, &#39;482c414d41f54cd18b22e5b47cb7c3cb&#39;],    ]</code></pre><p>修改url，把url变成file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz（这个是我下载的cifar10放置的位置）<br>之后运行</p><pre><code>import torchvision as tvimport torchvision.transforms as transformsfrom torchvision.transforms import ToPILImageimport torch.nn as nnimport torch.nn.functional as Fimport torchshow = ToPILImage() # 可以把tensor转成Image，方便可视化transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])trainset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)testset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)(data, label) = trainset[100]print(classes[label])print(len(trainset))print(len(testset))</code></pre><pre><code>输出：Files already downloaded and verifiedFiles already downloaded and verifiedship5000010000</code></pre><h3 id="创建网络"><a href="#创建网络" class="headerlink" title="创建网络"></a>创建网络</h3><pre><code>class Net_my(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1  = nn.Conv2d(3, 6, 5)        self.conv2  = nn.Conv2d(6, 16, 5)        self.fc1    = nn.Linear(16*5*5, 120)        self.fc2    = nn.Linear(120, 84)        self.fc3    = nn.Linear(84, 10)    def forward(self, x):        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))        x = F.max_pool2d(F.relu(self.conv2(x)), 2)        x = x.view(x.size()[0], -1)        x = F.relu(self.fc1(x))        x = F.relu(self.fc2(x))        x = self.fc3(x)        return x</code></pre><p>本来报错：</p><blockquote><p>class Net_my(nn.modules):<br>TypeError: module.<strong>init</strong>() takes at most 2 arguments (3 given)</p></blockquote><p>nn.modules -&gt; nn.Module就ok了。</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>报错</p><blockquote><p>BrokenPipeError: [Errno 32] Broken pipe</p></blockquote><p> 好像是win10的多线程导致的，需要避免windows使用多线程。把torch.utils.data.DataLoader()函数时的 num_workers 参数改成0。</p><blockquote><p>RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same</p></blockquote><p>要么都是cpu，要么都是gpu，需要统一</p><blockquote><p>net.cuda()<br>device = torch.device(“cuda:0” if torch.cuda.is_available() else “cpu”)<br>#网络和输入的数据都需要转成gpu或者cpu。</p></blockquote><p>可以训练</p><pre><code># net = Net()# net.cuda()# from torch import optim# criterion = nn.CrossEntropyLoss()# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)# device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)## torch.set_num_threads(8)# for epoch in range(10):#     running_loss = 0.0#     total = 0#     correct = 0#     for i, data in enumerate(trainloader, 0):#         inputs, labels = data#         inputs, labels = inputs.to(device),labels.to(device)##         optimizer.zero_grad()#         outputs = net(inputs)#         loss = criterion(outputs, labels)#         loss.backward()##         optimizer.step()##         running_loss += loss.item()##         if i % 2000 == 1999:#             print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch+1, i+1, running_loss / 2000))#             running_loss = 0.0#             _, predicted = torch.max(outputs, 1)#             total += labels.size(0)#             correct += (predicted == labels).sum().item()#             print(&#39;accuracy of the network on the %d train images: %.3f %%&#39; % (total, 100.0 * correct / total))#             total = 0#             correct = 0## print(&#39;Finished Training&#39;)</code></pre><h3 id="使用预训练模型来图像分类"><a href="#使用预训练模型来图像分类" class="headerlink" title="使用预训练模型来图像分类"></a>使用预训练模型来图像分类</h3><pre><code>import torchvision as tvimport torchvision.transforms as transformsfrom torchvision.transforms import ToPILImageimport torch.nn as nnimport torch.nn.functional as Fimport torchfrom torchvision import modelsfrom PIL import Imagealexnet = models.alexnet(pretrained=True)print(alexnet)img = Image.open(&#39;1.jpg&#39;)transform = transforms.Compose([            #[1] transforms.Resize(256),                    #[2] transforms.CenterCrop(224),                #[3] transforms.ToTensor(),                     #[4] transforms.Normalize(                      #[5] mean=[0.485, 0.456, 0.406],                #[6] std=[0.229, 0.224, 0.225]                  #[7] )])img_t = transform(img)batch_t = torch.unsqueeze(img_t, 0)alexnet.eval()out = alexnet(batch_t)with open(&#39;imagenet_classes.txt&#39;) as f:    classes = [line.strip() for line in f.readlines()]_, indices = torch.sort(out, descending=True)percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100[print(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]</code></pre><pre><code>输出655: &#39;miniskirt, mini&#39;, 10.492936134338379765: &#39;rocking chair, rocker&#39;, 4.194277286529541545: &#39;electric fan, blower&#39;, 4.150004863739014411: &#39;apron&#39;, 2.946284532546997589: &#39;hand blower, blow dryer, blow drier, hair dryer, hair drier&#39;, 2.749168872833252</code></pre><h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><pre><code>import torchimport torchvisionimport torchvision.transforms as transformsdevice = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)# 使用torchvision加载并且归一化CIFAR10的训练和测试数据集transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0)testset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)# 显示一批图像import matplotlib.pyplot as pltimport numpy as npdef imshow(img):    img = img / 2 + 0.5    npimg = img.numpy()    plt.imshow(np.transpose(npimg, (1, 2, 0)))    plt.show()dataiter = iter(trainloader)images, labels = dataiter.next()#imshow(torchvision.utils.make_grid(images))print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))# 定义一个卷积神经网络import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1 = nn.Conv2d(3, 6, 5)        self.pool = nn.MaxPool2d(2, 2)        self.conv2 = nn.Conv2d(6, 16, 5)        self.fc1 = nn.Linear(16 * 5 * 5, 120)        self.fc2 = nn.Linear(120, 84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        x = self.pool(F.relu(self.conv1(x)))        x = self.pool(F.relu(self.conv2(x)))        x = x.view(-1, 16 * 5 * 5)        x = F.relu(self.fc1(x))        x = F.relu(self.fc2(x))        x = self.fc3(x)        return xnet = Net()net.to(device)# 定义一个损失函数和优化器 让我们使用分类交叉熵Cross-Entropy 作损失函数，动量SGD做优化器。import torch.optim as optimcriterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)# 训练网络for epoch in range(5):    running_loss = 0.0    for i, data in enumerate(trainloader, 0):        inputs, labels = data        inputs, labels = inputs.to(device), labels.to(device)        optimizer.zero_grad()        outputs = net(inputs)        loss = criterion(outputs, labels)        loss.backward()        optimizer.step()        running_loss += loss.item()        if i % 1562 == 1555:            print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i + 1, running_loss / 2000))            running_loss = 0.0torch.save(net.state_dict(), &#39;model/cifar10.pkl&#39;)print(&#39;Finished Training&#39;)# 预测dataiter = iter(testloader)images, labels = dataiter.next()#imshow(torchvision.utils.make_grid(images))print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))images, labels = images.to(device), labels.to(device)#outputs = net(images)net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;))outputs = net(images)_, predicted = torch.max(outputs, 1)print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4)))# 整个数据集预测correct = 0total = 0with torch.no_grad():    for data in testloader:        images, labels = data        images, labels = images.to(device), labels.to(device)        #outputs = net(images)        net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;))        outputs = net(images)        _, predicted = torch.max(outputs.data, 1)        total += labels.size(0)        correct += (predicted == labels).sum().item()print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct / total))# 最后测试准确率在53%左右</code></pre>]]></content>
      
      
      <categories>
          
          <category> 图像分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跑通图像压缩算法SReC</title>
      <link href="2020/12/03/srec/"/>
      <url>2020/12/03/srec/</url>
      
        <content type="html"><![CDATA[<pre><code>源码位置：https://github.com/caoscott/SReC</code></pre><h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h3><p>git clone <a href="mailto:&#103;&#105;&#x74;&#x40;&#103;&#x69;&#116;&#x68;&#117;&#98;&#46;&#99;&#x6f;&#x6d;">&#103;&#105;&#x74;&#x40;&#103;&#x69;&#116;&#x68;&#117;&#98;&#46;&#99;&#x6f;&#x6d;</a>:caoscott/SReC.git</p><h3 id="搭建环境，使用的是没有nvidia-docker的方法"><a href="#搭建环境，使用的是没有nvidia-docker的方法" class="headerlink" title="搭建环境，使用的是没有nvidia-docker的方法"></a>搭建环境，使用的是没有nvidia-docker的方法</h3><p>我是已经装了torch1.5.0 + torchvision0.6.0 + gpu的环境，接下来</p><ol><li><p>pip install -r requirements.txt</p></li><li><p>安装gcc，参考的是这个大佬的文章<a href="https://blog.csdn.net/qilimi1053620912/article/details/88573017">https://blog.csdn.net/qilimi1053620912/article/details/88573017</a><br>在windows10上安装gcc。</p></li><li><p>运行COMPILE_CUDA=force python3 setup.py install，报错</p><blockquote><p>error: command ‘C:\Program Files (x86)\Microsoft Visual Studio\2017\Communit<br>y\VC\Tools\MSVC\14.16.27023\bin\HostX86\x64\cl.exe’ failed with exit sta<br>tus 2</p></blockquote></li></ol>]]></content>
      
      
      <categories>
          
          <category> 跑过的算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像压缩 </tag>
            
            <tag> 图像处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>supervisor + scrapy + python</title>
      <link href="2020/11/26/supervisor-scrapy-python/"/>
      <url>2020/11/26/supervisor-scrapy-python/</url>
      
        <content type="html"><![CDATA[<p>在ubuntu16.04下，首先爬取新浪微博的话题和关键词，然后会返回爬到的微博用户id，bid，和图像url。<br>之后再把这些图像送到深度学习所做的图像侵权检测系统，判断是否侵权我们的素材，返回相关的信息。</p><p>1.图像侵权检测</p><p>2.python 开启http服务</p><p>3.scrapy 爬取新浪微博</p><p>4.supervisor 进程管理</p><p>其实123慢慢调好了，这周调的最多的是怎么把1234放在一起，碰到了相当多的问题。</p><h3 id="开启supervisor-执行的命令可以是虚拟环境的命令，需要加上路径"><a href="#开启supervisor-执行的命令可以是虚拟环境的命令，需要加上路径" class="headerlink" title="开启supervisor 执行的命令可以是虚拟环境的命令，需要加上路径"></a>开启supervisor 执行的命令可以是虚拟环境的命令，需要加上路径</h3><p>比如</p><blockquote><p>[program:ibaotu-image-match]<br>command=<strong>/usr/local/data/anaconda3/envs/snakes/bin/python</strong> /usr/local/data/www/weibo_search_master/http_server_GET.py<br>directory=/usr/local/data/www/weibo_search_master<br>autostart=true<br>autorestart=true<br>stdout_logfile=/usr/local/data/www/log/out.log<br>stderr_logfile=/usr/local/data/www/log/err.log</p></blockquote><p>执行命令的时候就知道是执行哪里的python了</p><p>还可以web查看管理supervisor</p><blockquote><p>[inet_http_server] ; inet (TCP) server disabled by default<br>port=*:9001 ; (ip_address:port specifier, *:port for all iface)<br>;username=admin ; (default is no username (open server))<br>;password=admin ; (default is no password (open server))</p></blockquote><h3 id="supervisor命令"><a href="#supervisor命令" class="headerlink" title="supervisor命令"></a>supervisor命令</h3><p>查看状态<br>supervisorctl status<br>更新<br>supervisorctl update<br>重置<br>supervisorctl reload<br>结束<br>supervisorctl stop all<br>开始<br>supervisorctl start all<br>更新配置<br>supervisord -c /etc/supervisord/supervisord.conf</p><h3 id="遇到的报错"><a href="#遇到的报错" class="headerlink" title="遇到的报错"></a>遇到的报错</h3><blockquote><p>unix:///var/run/supervisor.sock no such file</p></blockquote><p>1.sudo touch /var/run/supervisor.sock</p><p>2.sudo chmod 777 /var/run/supervisor.sock</p><p>3.sudo service supervisor restart</p><blockquote><p>unix:///var/run/supervisor/supervisor.sock refused connection</p></blockquote><p>supervisord -c /etc/supervisord/supervisord.conf<br>启动supervisord并使用配置</p><blockquote><p>The ‘supervisor==3.2.0’ distribution was not found and is required by the application</p></blockquote><p>如果默认的python是python2,应该不会报错。如果是python3，就要修改<br>和terminator一样也是python版本引起的，编辑/usr/bin/supervisord将#!/usr/bin/python修改为#!/usr/bin/python2即可<br>貌似启动supervisor 只能用python2</p><blockquote><p>supervisord不能正常地话，查看它的log</p></blockquote><p>supervisorctl tail ibaotu-image-match stderr</p><blockquote><p>supervisorctl 启动起来，一直在报错重启， OSError: [Errno 98] Address already in use</p></blockquote><p>1.<br>netstat -tunlp<br>kill -9 6153<br>这个是每次都要这样，有点烦<br>2.<br>find / -name supervisor.sock<br>unlink /name/supervisor.sock</p><blockquote><p>root@ibaotu-algo:/usr/bin# scrapy<br>Traceback (most recent call last):<br>  File “/usr/local/bin/scrapy”, line 7, in <module><br>    from scrapy.cmdline import execute<br>  File “/usr/local/lib/python3.5/dist-packages/scrapy/<strong>init</strong>.py”, line 12, in <module><br>    from scrapy.spiders import Spider<br>  File “/usr/local/lib/python3.5/dist-packages/scrapy/spiders/<strong>init</strong>.py”, line 22<br>    name: Optional[str] = None<br>        ^<br>SyntaxError: invalid syntax</p></blockquote><p>在虚拟环境是好的，但是放在一起跑就出问题了。我研究了好久，才发现还是命令路径的问题。<br>在终端输入scrapy，虚拟环境是ok的，在普通的就报错。两个scrapy版本是一样的，<br>只不过虚拟环境的python是3.6.5，普通的python是3.5.2，不知道是不是和这个有关。<br>把scrapy改成/usr/local/data/anaconda3/envs/snakes/bin/scrapy</p><blockquote><p>scrapy是命令行，怎么在代码里面添加？</p></blockquote><pre><code>#cmdline.execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;search&quot;, &quot;-a&quot;, &quot;start_date=%s&quot;%(start_date), &quot;-a&quot;, &quot;end_date=%s&quot;%(end_date), &quot;-a&quot;, &quot;keyword_list=%s&quot;%(keyword)])cmd = &quot;/usr/local/data/anaconda3/envs/snakes/bin/scrapy crawl search -a &quot; + &quot;start_date=%s&quot;%(start_date) + &quot; -a &quot; + &quot;end_date=%s&quot;%(end_date) + &quot; -a &quot; + &quot;keyword_list=%s&quot;%(keyword)os.system(cmd)</code></pre><blockquote><p>开启的http服务，客户请求爬虫，怎么把数据返回？</p></blockquote><p>一开始的想法是能不能搞个全局变量。怎么搞也搞不过去，<br>python跨文件的全局变量，后面知道scrapy是新开的进程，数据根本到不了。<br>后面把数据存到csv或者json文件，爬完再读取，再返回。</p><blockquote><p>no module named …</p></blockquote><p>因为路径的问题，也搞了好久，明明都添加了，还是报错，sys.path.append()<br>最后因为没有使用到全局变量，这个报错也就不了了之了。</p><blockquote><p>遍历字典，写入csv，一个数据固定的写入一行</p></blockquote><p>writer.writerow([item[‘weibo’][key] for key in item[‘weibo’].keys() if key == ‘id’ or key == ‘bid’ or key == ‘pics’])</p><blockquote><p>是csv转成json，还是直接爬取pipeline到json</p></blockquote><p>我选择了后者，爬取了json格式的文件下来，包括id，bid，picurl组成的json格式的数据。<br>一开始json格式还写不进去，应该是格式问题，我弄了data格式，之后ok了。</p><pre><code>with codecs.open(jsonfile_path, &#39;a+&#39;) as f:    data = &#123;    &#39;id&#39;: item[&#39;weibo&#39;][&#39;user_id&#39;],    &#39;bid&#39;: item[&#39;weibo&#39;][&#39;bid&#39;],    &#39;screen_name&#39;: item[&#39;weibo&#39;][&#39;screen_name&#39;],    &#39;pics&#39;: item[&#39;weibo&#39;][&#39;pics&#39;]    &#125;    lines = json.dumps(data, ensure_ascii=False)    f.write(lines + &quot;\n&quot;)</code></pre><blockquote><p>然后也出现supervisor一直重启的问题</p></blockquote><p>因为配置中restart:默认为true，然后一直有htpp进程开着，报错OSError: [Errno 98] Address already in use；还有个原因就是原来的程序不是死循环，一会运行结束，又重启了。</p><h3 id="最后这个1234基本就能愉快地在一起玩耍了。"><a href="#最后这个1234基本就能愉快地在一起玩耍了。" class="headerlink" title="最后这个1234基本就能愉快地在一起玩耍了。"></a>最后这个1234基本就能愉快地在一起玩耍了。</h3>]]></content>
      
      
      <categories>
          
          <category> 项目经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conda的使用</title>
      <link href="2020/11/23/conda-de-shi-yong/"/>
      <url>2020/11/23/conda-de-shi-yong/</url>
      
        <content type="html"><![CDATA[<h3 id="安装Anaconda"><a href="#安装Anaconda" class="headerlink" title="安装Anaconda"></a>安装Anaconda</h3><p>首先需要安装anaconda，在不同的电脑上下载使用很多次了，还是挺方便的。正好开通了博客，就记录下conda的使用。</p><h3 id="conda-创建虚拟环境"><a href="#conda-创建虚拟环境" class="headerlink" title="conda 创建虚拟环境"></a>conda 创建虚拟环境</h3><p>anaconda安装成功之后，如果不成功，网上很多安装的博客可以查看。应该有conda命令了。</p><p><code>conda -V</code></p><p>返回<code>conda 4.7.12</code></p><h5 id="1-创建虚拟环境"><a href="#1-创建虚拟环境" class="headerlink" title="1.创建虚拟环境"></a>1.创建虚拟环境</h5><p>命令：<br><code>conda create --name pytorch python=3.6.5</code></p><p>安装总是失败</p><pre><code>Collecting package metadata (current_repodata.json): ...working... doneSolving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.Collecting package metadata (repodata.json): ...working...</code></pre><p>我添加了conda换源，可是还是不行</p><pre><code>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes</code></pre><p>修改命令<br><code>conda create --name pytorch python=3.6</code></p><pre><code>$ conda create -n tensorflow python=3.6.5Collecting package metadata (repodata.json): doneSolving environment: done==&gt; WARNING: A newer version of conda exists. &lt;==  current version: 4.8.3  latest version: 4.9.2Please update conda by running    $ conda update -n base -c defaults conda## Package Plan ##  environment location: C:\Users\DELL\Anaconda3\envs\tensorflow  added / updated specs:    - python=3.6.5The following packages will be downloaded:    package                    |            build    ---------------------------|-----------------    certifi-2020.11.8          |   py36haa95532_0         151 KB    pip-20.2.4                 |   py36haa95532_0         2.1 MB    python-3.6.5               |       h0c2934d_0        21.6 MB    setuptools-50.3.1          |   py36haa95532_1         939 KB    vc-14.1                    |       h0510ff6_4           6 KB    vs2015_runtime-14.16.27012 |       hf0eaf9b_3         2.4 MB    wincertstore-0.2           |   py36h7fe50ca_0          13 KB    ------------------------------------------------------------                                           Total:        27.2 MBThe following NEW packages will be INSTALLED:done## To activate this environment, use##     $ conda activate tensorflow## To deactivate an active environment, use##     $ conda deactivate</code></pre><p>2.安装成功之后，可以查看确认下<code>conda env list</code></p><h3 id="conda-进入虚拟环境"><a href="#conda-进入虚拟环境" class="headerlink" title="conda 进入虚拟环境"></a>conda 进入虚拟环境</h3><p>conda activate tensorflow<br>或者<br>source activate tensorflow</p><h3 id="conda-退出虚拟环境"><a href="#conda-退出虚拟环境" class="headerlink" title="conda 退出虚拟环境"></a>conda 退出虚拟环境</h3><p>conda deactivate<br>或者试试source deactivate<br>没有退出，就多输入几次命令</p><h3 id="conda-添加镜像"><a href="#conda-添加镜像" class="headerlink" title="conda 添加镜像"></a>conda 添加镜像</h3><p>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</a><br>conda config –add channels <a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/">https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/</a><br>#显示安装的镜像<br>conda config –set show_channel_urls yes<br>#已添加的channel在哪里查看<br>.condarc</p><h3 id="conda-删除虚拟环境"><a href="#conda-删除虚拟环境" class="headerlink" title="conda 删除虚拟环境"></a>conda 删除虚拟环境</h3><p>conda remove -n tensorflow –all</p><pre><code>conda remove -n tensorflow --allRemove all packages in environment C:\Users\DELL\Anaconda3\envs\tensorflow:## Package Plan ##  environment location: C:\Users\DELL\Anaconda3\envs\tensorflowThe following packages will be REMOVED:  certifi-2020.11.8-py36haa95532_0  pip-20.2.4-py36haa95532_0  python-3.6.5-h0c2934d_0  setuptools-50.3.1-py36haa95532_1  vc-14.1-h0510ff6_4  vs2015_runtime-14.16.27012-hf0eaf9b_3  wheel-0.35.1-pyhd3eb1b0_0  wincertstore-0.2-py36h7fe50ca_0Proceed ([y]/n)? yPreparing transaction: doneVerifying transaction: doneExecuting transaction: done</code></pre><p>我正常用的就是这些命令，记录一下。</p>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> anaconda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开发工具</title>
      <link href="2020/11/19/kai-fa-gong-ju/"/>
      <url>2020/11/19/kai-fa-gong-ju/</url>
      
        <content type="html"><![CDATA[<h3 id="这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。"><a href="#这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。" class="headerlink" title="这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。"></a>这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。</h3><h2 id="编辑器：Atom-（使用体验超级好）"><a href="#编辑器：Atom-（使用体验超级好）" class="headerlink" title="编辑器：Atom （使用体验超级好）"></a>编辑器：Atom （使用体验超级好）</h2><h4 id="Packages："><a href="#Packages：" class="headerlink" title="Packages："></a>Packages：</h4><p>1.Hydropen<br>2.activate_power_mode<br>3.atom_python_run<br>4.atom_terminal<br>5.autocomplete-python<br>6.hyperclick<br>7.ide-python<br><strong>8.kite # 特别好用，使用有惊喜</strong><br>9.minimap<br>10.python-tools<br>11.run-in-terminal<br>其他很多包全是core packages，不进行列举。</p><h2 id="远程连接传输工具：Xshell-Winscp-Putty"><a href="#远程连接传输工具：Xshell-Winscp-Putty" class="headerlink" title="远程连接传输工具：Xshell Winscp Putty"></a>远程连接传输工具：Xshell Winscp Putty</h2><h2 id="Coding：Pycharm-Anaconda-Visual-Studio-Source-Insight"><a href="#Coding：Pycharm-Anaconda-Visual-Studio-Source-Insight" class="headerlink" title="Coding：Pycharm Anaconda Visual-Studio Source-Insight"></a>Coding：Pycharm Anaconda Visual-Studio Source-Insight</h2><h2 id="数据库：HeidiSQL"><a href="#数据库：HeidiSQL" class="headerlink" title="数据库：HeidiSQL"></a>数据库：HeidiSQL</h2><h2 id="查看神经网络的结构：Netron"><a href="#查看神经网络的结构：Netron" class="headerlink" title="查看神经网络的结构：Netron"></a>查看神经网络的结构：Netron</h2><h2 id="Cuda：v10-0"><a href="#Cuda：v10-0" class="headerlink" title="Cuda：v10.0"></a>Cuda：v10.0</h2><h2 id="Cudnn：v7-6-5"><a href="#Cudnn：v7-6-5" class="headerlink" title="Cudnn：v7.6.5"></a>Cudnn：v7.6.5</h2><h2 id="查看windows文件：listary"><a href="#查看windows文件：listary" class="headerlink" title="查看windows文件：listary"></a>查看windows文件：listary</h2>]]></content>
      
      
      <categories>
          
          <category> 开发工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>categories</title>
      <link href="categories/index.html"/>
      <url>categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>about</title>
      <link href="about/index.html"/>
      <url>about/index.html</url>
      
        <content type="html"><![CDATA[<p>我是小骨子，欢迎您</p>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="tags/index.html"/>
      <url>tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>contact</title>
      <link href="contact/index.html"/>
      <url>contact/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
