{"meta":{"title":"小骨子还在努力","subtitle":"还在努力","description":"","author":"xiao hong zhong","url":"http://xiaohongzhong.top","root":"/"},"pages":[{"title":"about","date":"2020-11-18T06:59:25.000Z","updated":"2020-11-19T01:30:32.000Z","comments":true,"path":"about/index.html","permalink":"http://xiaohongzhong.top/about/index.html","excerpt":"","text":"我是小骨子，欢迎您"},{"title":"categories","date":"2020-11-18T06:58:54.000Z","updated":"2020-11-18T08:00:20.000Z","comments":true,"path":"categories/index.html","permalink":"http://xiaohongzhong.top/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2020-11-22T11:54:42.000Z","updated":"2020-11-22T11:55:46.000Z","comments":true,"path":"contact/index.html","permalink":"http://xiaohongzhong.top/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-11-18T06:58:27.000Z","updated":"2020-11-18T08:09:12.000Z","comments":true,"path":"tags/index.html","permalink":"http://xiaohongzhong.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"图像分类-CIFAR10-Pytorch","slug":"图像分类-CIFAR10-Pytorch","date":"2020-12-04T02:13:46.000Z","updated":"2020-12-08T03:01:40.496Z","comments":true,"path":"2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/","link":"","permalink":"http://xiaohongzhong.top/2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/","excerpt":"想要使用pytorch，就从最基础的图像分类，也是最熟悉的图像分类开始。","text":"想要使用pytorch，就从最基础的图像分类，也是最熟悉的图像分类开始。 这是官网中文中的代码 http://pytorch123.com/SecondSection/training_a_classifier/ 数据集如果直接从源代码下载CIFAR10数据集，本来就只有160M，结果下载一天也没下载好，下载太慢。建议从网上寻找数据集。 下载完之后，需要修改源码内容。打开我在anaconda下安装torch的虚拟环境，找到torchvision的包，在datasets文件夹下面有个cifar.py C:\\Users\\DELL\\Anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\datasets\\cifar.py class CIFAR10(VisionDataset): &quot;&quot;&quot;`CIFAR10 &lt;https://www.cs.toronto.edu/~kriz/cifar.html&gt;`_ Dataset. Args: root (string): Root directory of dataset where directory ``cifar-10-batches-py`` exists or will be saved to if download is set to True. train (bool, optional): If True, creates dataset from training set, otherwise creates from test set. transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed version. E.g, ``transforms.RandomCrop`` target_transform (callable, optional): A function/transform that takes in the target and transforms it. download (bool, optional): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. &quot;&quot;&quot; base_folder = &#39;cifar-10-batches-py&#39; #url = &quot;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&quot; url = &quot;file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz&quot; filename = &quot;cifar-10-python.tar.gz&quot; tgz_md5 = &#39;c58f30108f718f92721af3b95e74349a&#39; train_list = [ [&#39;data_batch_1&#39;, &#39;c99cafc152244af753f735de768cd75f&#39;], [&#39;data_batch_2&#39;, &#39;d4bba439e000b95fd0a9bffe97cbabec&#39;], [&#39;data_batch_3&#39;, &#39;54ebc095f3ab1f0389bbae665268c751&#39;], [&#39;data_batch_4&#39;, &#39;634d18415352ddfa80567beed471001a&#39;], [&#39;data_batch_5&#39;, &#39;482c414d41f54cd18b22e5b47cb7c3cb&#39;], ] 修改url，把url变成file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz（这个是我下载的cifar10放置的位置）之后运行 import torchvision as tv import torchvision.transforms as transforms from torchvision.transforms import ToPILImage import torch.nn as nn import torch.nn.functional as F import torch show = ToPILImage() # 可以把tensor转成Image，方便可视化 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) trainset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;) (data, label) = trainset[100] print(classes[label]) print(len(trainset)) print(len(testset)) 输出： Files already downloaded and verified Files already downloaded and verified ship 50000 10000 创建网络class Net_my(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(x.size()[0], -1) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x 本来报错： class Net_my(nn.modules):TypeError: module.init() takes at most 2 arguments (3 given) nn.modules -&gt; nn.Module就ok了。 训练报错 BrokenPipeError: [Errno 32] Broken pipe 好像是win10的多线程导致的，需要避免windows使用多线程。把torch.utils.data.DataLoader()函数时的 num_workers 参数改成0。 RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same 要么都是cpu，要么都是gpu，需要统一 net.cuda()device = torch.device(“cuda:0” if torch.cuda.is_available() else “cpu”)#网络和输入的数据都需要转成gpu或者cpu。 可以训练 # net = Net() # net.cuda() # from torch import optim # criterion = nn.CrossEntropyLoss() # optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) # # torch.set_num_threads(8) # for epoch in range(10): # running_loss = 0.0 # total = 0 # correct = 0 # for i, data in enumerate(trainloader, 0): # inputs, labels = data # inputs, labels = inputs.to(device),labels.to(device) # # optimizer.zero_grad() # outputs = net(inputs) # loss = criterion(outputs, labels) # loss.backward() # # optimizer.step() # # running_loss += loss.item() # # if i % 2000 == 1999: # print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch+1, i+1, running_loss / 2000)) # running_loss = 0.0 # _, predicted = torch.max(outputs, 1) # total += labels.size(0) # correct += (predicted == labels).sum().item() # print(&#39;accuracy of the network on the %d train images: %.3f %%&#39; % (total, 100.0 * correct / total)) # total = 0 # correct = 0 # # print(&#39;Finished Training&#39;) 使用预训练模型来图像分类import torchvision as tv import torchvision.transforms as transforms from torchvision.transforms import ToPILImage import torch.nn as nn import torch.nn.functional as F import torch from torchvision import models from PIL import Image alexnet = models.alexnet(pretrained=True) print(alexnet) img = Image.open(&#39;1.jpg&#39;) transform = transforms.Compose([ #[1] transforms.Resize(256), #[2] transforms.CenterCrop(224), #[3] transforms.ToTensor(), #[4] transforms.Normalize( #[5] mean=[0.485, 0.456, 0.406], #[6] std=[0.229, 0.224, 0.225] #[7] )]) img_t = transform(img) batch_t = torch.unsqueeze(img_t, 0) alexnet.eval() out = alexnet(batch_t) with open(&#39;imagenet_classes.txt&#39;) as f: classes = [line.strip() for line in f.readlines()] _, indices = torch.sort(out, descending=True) percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100 [print(classes[idx], percentage[idx].item()) for idx in indices[0][:5]] 输出 655: &#39;miniskirt, mini&#39;, 10.492936134338379 765: &#39;rocking chair, rocker&#39;, 4.194277286529541 545: &#39;electric fan, blower&#39;, 4.150004863739014 411: &#39;apron&#39;, 2.946284532546997 589: &#39;hand blower, blow dryer, blow drier, hair dryer, hair drier&#39;, 2.749168872833252 完整代码import torch import torchvision import torchvision.transforms as transforms device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) # 使用torchvision加载并且归一化CIFAR10的训练和测试数据集 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) trainset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0) testset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0) classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;) # 显示一批图像 import matplotlib.pyplot as plt import numpy as np def imshow(img): img = img / 2 + 0.5 npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) plt.show() dataiter = iter(trainloader) images, labels = dataiter.next() #imshow(torchvision.utils.make_grid(images)) print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) # 定义一个卷积神经网络 import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() net.to(device) # 定义一个损失函数和优化器 让我们使用分类交叉熵Cross-Entropy 作损失函数，动量SGD做优化器。 import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 训练网络 for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 1562 == 1555: print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 torch.save(net.state_dict(), &#39;model/cifar10.pkl&#39;) print(&#39;Finished Training&#39;) # 预测 dataiter = iter(testloader) images, labels = dataiter.next() #imshow(torchvision.utils.make_grid(images)) print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) images, labels = images.to(device), labels.to(device) #outputs = net(images) net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;)) outputs = net(images) _, predicted = torch.max(outputs, 1) print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4))) # 整个数据集预测 correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data images, labels = images.to(device), labels.to(device) #outputs = net(images) net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;)) outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct / total)) # 最后测试准确率在53%左右","categories":[{"name":"图像分类","slug":"图像分类","permalink":"http://xiaohongzhong.top/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://xiaohongzhong.top/tags/Pytorch/"},{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"跑通图像压缩算法SReC","slug":"SReC","date":"2020-12-03T06:41:52.000Z","updated":"2020-12-08T02:22:12.605Z","comments":true,"path":"2020/12/03/srec/","link":"","permalink":"http://xiaohongzhong.top/2020/12/03/srec/","excerpt":"源码位置：https://github.com/caoscott/SReC","text":"源码位置：https://github.com/caoscott/SReC 下载源码git clone &#x67;&#105;&#116;&#64;&#103;&#105;&#116;&#104;&#x75;&#x62;&#x2e;&#x63;&#111;&#109;:caoscott/SReC.git 搭建环境，使用的是没有nvidia-docker的方法我是已经装了torch1.5.0 + torchvision0.6.0 + gpu的环境，接下来 pip install -r requirements.txt 安装gcc，参考的是这个大佬的文章https://blog.csdn.net/qilimi1053620912/article/details/88573017在windows10上安装gcc。 运行COMPILE_CUDA=force python3 setup.py install，报错 error: command ‘C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x64\\cl.exe’ failed with exit status 2","categories":[{"name":"跑过的算法","slug":"跑过的算法","permalink":"http://xiaohongzhong.top/categories/%E8%B7%91%E8%BF%87%E7%9A%84%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"图像压缩","slug":"图像压缩","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/"},{"name":"图像处理","slug":"图像处理","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"supervisor + scrapy + python","slug":"supervisor-scrapy-python","date":"2020-11-26T06:42:57.000Z","updated":"2020-12-08T02:22:14.779Z","comments":true,"path":"2020/11/26/supervisor-scrapy-python/","link":"","permalink":"http://xiaohongzhong.top/2020/11/26/supervisor-scrapy-python/","excerpt":"","text":"在ubuntu16.04下最近在做一个项目，它是在服务器部署，首先我们的人员请求爬取新浪微博的话题和关键词，然后会返回爬到的微博用户id，bid，和图像url。之后再把这些图像送到深度学习所做的图像侵权检测系统，判断是否侵权我们的素材，返回相关的信息。 1.图像侵权检测 2.python 开启http服务 3.scrapy 爬取新浪微博 4.supervisor 进程管理 其实123慢慢调好了，这周调的最多的是怎么把1234放在一起，碰到了相当多的问题。 开启supervisor 执行的命令可以是虚拟环境的命令，需要加上路径比如 [program:ibaotu-image-match]command=/usr/local/data/anaconda3/envs/snakes/bin/python /usr/local/data/www/weibo_search_master/http_server_GET.pydirectory=/usr/local/data/www/weibo_search_masterautostart=trueautorestart=truestdout_logfile=/usr/local/data/www/log/out.logstderr_logfile=/usr/local/data/www/log/err.log 执行命令的时候就知道是执行哪里的python了 还可以web查看管理supervisor [inet_http_server] ; inet (TCP) server disabled by defaultport=*:9001 ; (ip_address:port specifier, *:port for all iface);username=admin ; (default is no username (open server));password=admin ; (default is no password (open server)) supervisor命令查看状态supervisorctl status更新supervisorctl update重置supervisorctl reload结束supervisorctl stop all开始supervisorctl start all更新配置supervisord -c /etc/supervisord/supervisord.conf 遇到的报错 unix:///var/run/supervisor.sock no such file 1.sudo touch /var/run/supervisor.sock 2.sudo chmod 777 /var/run/supervisor.sock 3.sudo service supervisor restart unix:///var/run/supervisor/supervisor.sock refused connection supervisord -c /etc/supervisord/supervisord.conf启动supervisord并使用配置 The ‘supervisor==3.2.0’ distribution was not found and is required by the application 如果默认的python是python2,应该不会报错。如果是python3，就要修改和terminator一样也是python版本引起的，编辑/usr/bin/supervisord将#!/usr/bin/python修改为#!/usr/bin/python2即可貌似启动supervisor 只能用python2 supervisord不能正常地话，查看它的log supervisorctl tail ibaotu-image-match stderr supervisorctl 启动起来，一直在报错重启， OSError: [Errno 98] Address already in use 1.netstat -tunlpkill -9 6153这个是每次都要这样，有点烦2.find / -name supervisor.sockunlink /name/supervisor.sock root@ibaotu-algo:/usr/bin# scrapyTraceback (most recent call last): File “/usr/local/bin/scrapy”, line 7, in from scrapy.cmdline import execute File “/usr/local/lib/python3.5/dist-packages/scrapy/init.py”, line 12, in from scrapy.spiders import Spider File “/usr/local/lib/python3.5/dist-packages/scrapy/spiders/init.py”, line 22 name: Optional[str] = None ^SyntaxError: invalid syntax 在虚拟环境是好的，但是放在一起跑就出问题了。我研究了好久，才发现还是命令路径的问题。在终端输入scrapy，虚拟环境是ok的，在普通的就报错。两个scrapy版本是一样的，只不过虚拟环境的python是3.6.5，普通的python是3.5.2，不知道是不是和这个有关。把scrapy改成/usr/local/data/anaconda3/envs/snakes/bin/scrapy scrapy是命令行，怎么在代码里面添加？ #cmdline.execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;search&quot;, &quot;-a&quot;, &quot;start_date=%s&quot;%(start_date), &quot;-a&quot;, &quot;end_date=%s&quot;%(end_date), &quot;-a&quot;, &quot;keyword_list=%s&quot;%(keyword)]) cmd = &quot;/usr/local/data/anaconda3/envs/snakes/bin/scrapy crawl search -a &quot; + &quot;start_date=%s&quot;%(start_date) + &quot; -a &quot; + &quot;end_date=%s&quot;%(end_date) + &quot; -a &quot; + &quot;keyword_list=%s&quot;%(keyword) os.system(cmd) 开启的http服务，客户请求爬虫，怎么把数据返回？ 一开始的想法是能不能搞个全局变量。怎么搞也搞不过去，python跨文件的全局变量，后面知道scrapy是新开的进程，数据根本到不了。后面把数据存到csv或者json文件，爬完再读取，再返回。 no module named … 因为路径的问题，也搞了好久，明明都添加了，还是报错，sys.path.append()最后因为没有使用到全局变量，这个报错也就不了了之了。 遍历字典，写入csv，一个数据固定的写入一行 writer.writerow([item[‘weibo’][key] for key in item[‘weibo’].keys() if key == ‘id’ or key == ‘bid’ or key == ‘pics’]) 是csv转成json，还是直接爬取pipeline到json 我选择了后者，爬取了json格式的文件下来，包括id，bid，picurl组成的json格式的数据。一开始json格式还写不进去，应该是格式问题，我弄了data格式，之后ok了。 with codecs.open(jsonfile_path, &#39;a+&#39;) as f: data = &#123; &#39;id&#39;: item[&#39;weibo&#39;][&#39;user_id&#39;], &#39;bid&#39;: item[&#39;weibo&#39;][&#39;bid&#39;], &#39;screen_name&#39;: item[&#39;weibo&#39;][&#39;screen_name&#39;], &#39;pics&#39;: item[&#39;weibo&#39;][&#39;pics&#39;] &#125; lines = json.dumps(data, ensure_ascii=False) f.write(lines + &quot;\\n&quot;) 然后也出现supervisor一直重启的问题 因为配置中restart:默认为true，然后一直有htpp进程开着，报错OSError: [Errno 98] Address already in use；还有个原因就是原来的程序不是死循环，一会运行结束，又重启了。 最后这个1234基本就能愉快地在一起玩耍了。","categories":[{"name":"项目经验","slug":"项目经验","permalink":"http://xiaohongzhong.top/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://xiaohongzhong.top/tags/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"http://xiaohongzhong.top/tags/python/"}]},{"title":"Conda的使用","slug":"Conda的使用","date":"2020-11-23T13:00:20.000Z","updated":"2020-12-04T02:19:14.463Z","comments":true,"path":"2020/11/23/conda-de-shi-yong/","link":"","permalink":"http://xiaohongzhong.top/2020/11/23/conda-de-shi-yong/","excerpt":"安装Anaconda","text":"安装Anaconda 首先需要安装anaconda，在不同的电脑上下载使用很多次了，还是挺方便的。正好开通了博客，就记录下conda的使用。 conda 创建虚拟环境anaconda安装成功之后，如果不成功，网上很多安装的博客可以查看。应该有conda命令了。 conda -V 返回conda 4.7.12 1.创建虚拟环境命令：conda create --name pytorch python=3.6.5 安装总是失败 Collecting package metadata (current_repodata.json): ...working... done Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): ...working... 我添加了conda换源，可是还是不行 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes 修改命令conda create --name pytorch python=3.6 $ conda create -n tensorflow python=3.6.5 Collecting package metadata (repodata.json): done Solving environment: done ==&gt; WARNING: A newer version of conda exists. &lt;== current version: 4.8.3 latest version: 4.9.2 Please update conda by running $ conda update -n base -c defaults conda ## Package Plan ## environment location: C:\\Users\\DELL\\Anaconda3\\envs\\tensorflow added / updated specs: - python=3.6.5 The following packages will be downloaded: package | build ---------------------------|----------------- certifi-2020.11.8 | py36haa95532_0 151 KB pip-20.2.4 | py36haa95532_0 2.1 MB python-3.6.5 | h0c2934d_0 21.6 MB setuptools-50.3.1 | py36haa95532_1 939 KB vc-14.1 | h0510ff6_4 6 KB vs2015_runtime-14.16.27012 | hf0eaf9b_3 2.4 MB wincertstore-0.2 | py36h7fe50ca_0 13 KB ------------------------------------------------------------ Total: 27.2 MB The following NEW packages will be INSTALLED: done # # To activate this environment, use # # $ conda activate tensorflow # # To deactivate an active environment, use # # $ conda deactivate 2.安装成功之后，可以查看确认下conda env list conda 进入虚拟环境conda activate tensorflow或者source activate tensorflow conda 退出虚拟环境conda deactivate或者试试source deactivate没有退出，就多输入几次命令 conda 添加镜像conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/#显示安装的镜像conda config –set show_channel_urls yes#已添加的channel在哪里查看.condarc conda 删除虚拟环境conda remove -n tensorflow –all conda remove -n tensorflow --all Remove all packages in environment C:\\Users\\DELL\\Anaconda3\\envs\\tensorflow: ## Package Plan ## environment location: C:\\Users\\DELL\\Anaconda3\\envs\\tensorflow The following packages will be REMOVED: certifi-2020.11.8-py36haa95532_0 pip-20.2.4-py36haa95532_0 python-3.6.5-h0c2934d_0 setuptools-50.3.1-py36haa95532_1 vc-14.1-h0510ff6_4 vs2015_runtime-14.16.27012-hf0eaf9b_3 wheel-0.35.1-pyhd3eb1b0_0 wincertstore-0.2-py36h7fe50ca_0 Proceed ([y]/n)? y Preparing transaction: done Verifying transaction: done Executing transaction: done 我正常用的就是这些命令，记录一下。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://xiaohongzhong.top/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://xiaohongzhong.top/tags/anaconda/"}]},{"title":"开发工具","slug":"开发工具","date":"2020-11-19T06:28:49.000Z","updated":"2020-12-04T02:16:54.631Z","comments":true,"path":"2020/11/19/kai-fa-gong-ju/","link":"","permalink":"http://xiaohongzhong.top/2020/11/19/kai-fa-gong-ju/","excerpt":"这里是我日常使用的一些工具","text":"这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。编辑器：Atom （使用体验超级好）Packages：1.Hydropen2.activate_power_mode3.atom_python_run4.atom_terminal5.autocomplete-python6.hyperclick7.ide-python8.kite # 特别好用，使用有惊喜9.minimap10.python-tools11.run-in-terminal其他很多包全是core packages，不进行列举。 远程连接传输工具：Xshell Winscp PuttyCoding：Pycharm Anaconda Visual-Studio Source-Insight数据库：HeidiSQL查看神经网络的结构：NetronCuda：v10.0Cudnn：v7.6.5查看windows文件：listary","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://xiaohongzhong.top/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://xiaohongzhong.top/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-11-18T02:11:54.000Z","updated":"2020-12-08T02:14:34.689Z","comments":true,"path":"2020/11/18/hello-world/","link":"","permalink":"http://xiaohongzhong.top/2020/11/18/hello-world/","excerpt":"Welcome to Hexo!","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"图像分类","slug":"图像分类","permalink":"http://xiaohongzhong.top/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"},{"name":"跑过的算法","slug":"跑过的算法","permalink":"http://xiaohongzhong.top/categories/%E8%B7%91%E8%BF%87%E7%9A%84%E7%AE%97%E6%B3%95/"},{"name":"项目经验","slug":"项目经验","permalink":"http://xiaohongzhong.top/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C/"},{"name":"开发工具","slug":"开发工具","permalink":"http://xiaohongzhong.top/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://xiaohongzhong.top/tags/Pytorch/"},{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"图像压缩","slug":"图像压缩","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/"},{"name":"爬虫","slug":"爬虫","permalink":"http://xiaohongzhong.top/tags/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"http://xiaohongzhong.top/tags/python/"},{"name":"anaconda","slug":"anaconda","permalink":"http://xiaohongzhong.top/tags/anaconda/"},{"name":"工具","slug":"工具","permalink":"http://xiaohongzhong.top/tags/%E5%B7%A5%E5%85%B7/"}]}