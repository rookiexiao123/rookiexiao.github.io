{"meta":{"title":"小骨子还在努力","subtitle":"还在努力","description":"","author":"xiao hong zhong","url":"http://xiaohongzhong.top","root":"/"},"pages":[{"title":"about","date":"2020-11-18T06:59:25.000Z","updated":"2020-11-19T01:30:32.000Z","comments":true,"path":"about/index.html","permalink":"http://xiaohongzhong.top/about/index.html","excerpt":"","text":"我是小骨子，欢迎您"},{"title":"categories","date":"2020-11-18T06:58:54.000Z","updated":"2020-11-18T08:00:20.000Z","comments":true,"path":"categories/index.html","permalink":"http://xiaohongzhong.top/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2020-11-22T11:54:42.000Z","updated":"2020-11-22T11:55:46.000Z","comments":true,"path":"contact/index.html","permalink":"http://xiaohongzhong.top/contact/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-11-18T06:58:27.000Z","updated":"2020-11-18T08:09:12.000Z","comments":true,"path":"tags/index.html","permalink":"http://xiaohongzhong.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"RTX3080有什么不一样？","slug":"RTX3080有什么不一样？","date":"2020-12-17T14:21:55.000Z","updated":"2020-12-22T14:12:42.990Z","comments":true,"path":"2020/12/17/rtx3080-you-shi-me-bu-yi-yang/","link":"","permalink":"http://xiaohongzhong.top/2020/12/17/rtx3080-you-shi-me-bu-yi-yang/","excerpt":"","text":"title: RTX3080有什么不一样？date: 2020-12-17 22:21:55summary: 这里是我新电脑环境搭建的内容categories: 开发工具tags: 工具 开头想要说的是，每一台机器都有不同的配置，每一个配置都要装不同版本的软件。 显卡驱动怎么看显卡驱动-&gt;nvidia-smi 3080-&gt;nvidia-smi 456.81 cuda 11.1 cudnn 8.0.5 我之前用的电脑是rtx2070，配置是tensorflow-gpu 1.14 cuda10.0 cudnn7.6.5。 根据显卡驱动的不同，来安装不同的cuda。依据如下 https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html 安装了不同版本的cuda，再找配对的cudnn。 接下来看tensorflow的版本应该用哪个 https://tensorflow.google.cn/install/source_windows pytorch也找相对应的。cuda10.0就下载cuda10.0的，cuda10.1就用cuda10.1的，因为跑了一个算法，装的是cuda10.0，没有跑成功cuda10.1的pytorch。 怎么安装pytorch官网下载太慢 https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/win-64/ 运行 conda install pytorch-1.7.0-py3.6_cuda110_cudnn8_0.tar.bz2 之后运行 conda install pytorch-gpu torchvision-gpu -c pytorch torch1.7.0 cuda11.0 cudnn8.0 python3.6就装好了。 总是出现AttributeError: ‘str’ object has no attribute ‘decode’在运行keras很简单的图像分类时，总是出现AttributeError: ‘str’ object has no attribute ‘decode’tensorflow-cpu 1.14.0 解决方法：把出现decode(“utf-8”)的地方都去掉 D:\\software_install\\anaconda\\envs\\tensorflow-cpu\\Lib\\site-packages\\keras model.pyp242 model_config = json.loads(model_config.decode(‘utf-8’))p258 training_config = json.loads(training_config)D:\\software_install\\anaconda\\envs\\tensorflow-cpu\\Lib\\site-packages\\keras\\engine topology.pyp3372if ‘keras_version’ in f.attrs: original_keras_version = f.attrs[‘keras_version’].decode(‘utf8’)else: original_keras_version = ‘1’if ‘backend’ in f.attrs: original_backend = f.attrs[‘backend’].decode(‘utf8’)else: original_backend = None conda install 总是卡在solving environment更新conda到最新版本：conda update -n base conda 再查一下conda版本：conda -V 并不是最新版本conda 4.7.11 第二次更新conda到最新版本：conda update -n base conda 更新完后再查一下conda版本：conda -V，发现是最新版本conda 4.7.11 然后执行：conda update –all windows terminal颜值确实可以，我直接在Microsoft store下载的。碰见几个问题 右键添加有windows terminal的选项下载一个图标 https://gitee.com/Jioho/img/raw/master/wsl/terminal.ico 新建一个文件 Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\wt] @=&quot;Windows Terminal here&quot; &quot;Icon&quot;=&quot;%USERPROFILE%\\\\AppData\\\\Local\\\\Terminal\\\\terminal.ico&quot; [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\wt\\command] @=&quot;C:\\\\Users\\\\[你的电脑用户名！你的电脑用户名！]\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\wt.exe&quot; 双击 编辑 C:\\Users[用户名]\\AppData\\Local\\Packages\\Microsoft.WindowsTerminal_8wekyb3d8bbwe\\LocalState\\settings.json &#123; // Make changes here to the powershell.exe profile. &quot;guid&quot;: &quot;&#123;61c54bbd-c2c6-5271-96e7-009a87ff44bf&#125;&quot;, &quot;name&quot;: &quot;Windows PowerShell&quot;, &quot;commandline&quot;: &quot;powershell.exe &quot;, &quot;hidden&quot;: false &#125;, 改成： &#123; // Make changes here to the powershell.exe profile. &quot;guid&quot;: &quot;&#123;61c54bbd-c2c6-5271-96e7-009a87ff44bf&#125;&quot;, &quot;name&quot;: &quot;Windows PowerShell&quot;, &quot;commandline&quot;: &quot;powershell.exe &quot;, &quot;hidden&quot;: false, &quot;startingDirectory&quot;: &quot;.&quot; &#125;, 就ok了。 windows PS 进不去虚拟环境conda activate torch总是进不去，没有返回 解决：以管理员身份运行powershell 执行命令 Set-ExecutionPolicy RemoteSigned 然后打开powershell,输入conda init powershell，之后再打开就直接进入虚拟环境了。","categories":[],"tags":[]},{"title":"YOLOv3和YOLOv4的简单记录","slug":"YOLOv3和YOLOv4的简单记录","date":"2020-12-14T01:48:50.000Z","updated":"2020-12-16T12:36:29.708Z","comments":true,"path":"2020/12/14/yolov3-he-yolov4-de-jian-dan-ji-lu/","link":"","permalink":"http://xiaohongzhong.top/2020/12/14/yolov3-he-yolov4-de-jian-dan-ji-lu/","excerpt":"","text":"YOLOv4 https://github.com/Tianxiaomo/pytorch-YOLOv4 1.新建weight文件夹，把下载的权重放进去2.测试python demo.py -cfgfile cfg/yolov4.cfg -weightfile weight/yolov4.pth -imgfile data/dog.jpg 运行 3.cfg.py Cfg.use_darknet_cfg = False(把true改成false)结果： data/dog.jpg: Predicted in 0.088746 seconds. bicycle: 0.923744 truck: 0.917914 dog: 0.979061 save plot results to predictions.jpg 打开图片 创建自己的数据集 训练 python train.py -l 0.001 -g 0 -pretrained ./weight/yolov4.conv.137.pth -classes 2 -dir ./VOCdevkit/VOC2020/JPEGImages/ -train_label_path ./data/train.txt 报错：cv2.error: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-nxx381if\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function ‘cv::cvtColor’ 搞不定! YOLOv3 https://github.com/qqwweee/keras-yolo3 报错：keras版本yolov3提示str object has no attribute decode解决方法：pip install h5py==2.10 -i https://pypi.tuna.tsinghua.edu.cn/simple/ 步骤： 创建VOC数据集，把图片放在JPEGImages，xml标注文件放在Annotations文件夹中 生成Main中4个txt文件=&gt;python mktxt.py (注划分比例9：1) 修改voc_annotation.py生成3个txt文件=&gt;2020_train.txt，python voc_annotation.py 修改类别文件，model_data/voc_classes.txt 修改anchor文件，打开kmeans.py，filename修改2处，会得到9个anchors坐标和准确率，得到的值放进model_data/yolo_anchors.txt。python kmeans.py 修改yolov3.cfg，搜索yolo，classes改成对应，filter=3x(5 + classes) 修改train.py, python train.py","categories":[{"name":"跑过的算法","slug":"跑过的算法","permalink":"http://xiaohongzhong.top/categories/%E8%B7%91%E8%BF%87%E7%9A%84%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"目标检测","slug":"目标检测","permalink":"http://xiaohongzhong.top/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"python读写json使用经验","slug":"python读写json使用经验","date":"2020-12-11T06:42:44.000Z","updated":"2020-12-11T08:17:12.918Z","comments":true,"path":"2020/12/11/python-du-xie-json-shi-yong-jing-yan/","link":"","permalink":"http://xiaohongzhong.top/2020/12/11/python-du-xie-json-shi-yong-jing-yan/","excerpt":"","text":"目前在做的工作，对接需要用JSON格式，所以就记录了一些内容。 爬虫任务，需要把爬下来的数据以json格式转给对方。 在scrapy框架下，写入json格式的内容，保存.json文件 class JsonPipeline(object): def process_item(self, item, spider): base_dir = &#39;result&#39; + os.sep + item[&#39;keyword&#39;] if not os.path.isdir(base_dir): os.makedirs(base_dir) jsonfile_path = base_dir + os.sep + item[&#39;keyword&#39;] + &#39;.json&#39; if item: with codecs.open(jsonfile_path, &#39;a+&#39;) as f: data = &#123; &#39;id&#39;: item[&#39;weibo&#39;][&#39;user_id&#39;], &#39;bid&#39;: item[&#39;weibo&#39;][&#39;bid&#39;], &#39;screen_name&#39;: item[&#39;weibo&#39;][&#39;screen_name&#39;], &#39;pics&#39;: item[&#39;weibo&#39;][&#39;pics&#39;] &#125; lines = json.dumps(data, ensure_ascii=False) f.write(lines + &quot;\\n&quot;) return item 后面传输时，读取json文件，http返回给对方 json_bigdata = [] if keyword == &quot;[&#39;&#39;]&quot;: file_path = &#39;result/%23&#39; + str(topic.strip(&quot;#&quot;)) + &#39;%23/%23&#39; + str(topic.strip(&quot;#&quot;)) + &#39;%23.json&#39; try: with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp: for line in fp.readlines(): json_data = json.loads(line) json_bigdata.append(json_data) self.send_response(200) self.send_header(&#39;Content-Type&#39;, &#39;text/plain; charset=utf-8&#39;) self.end_headers() self.wfile.write(str(json_bigdata).encode(&#39;utf-8&#39;)) except: message_parts.append(&#39;&#39;) message = &#39;\\r\\n&#39;.join(message_parts) self.send_response(200) self.send_header(&#39;Content-Type&#39;, &#39;text/plain; charset=utf-8&#39;) self.end_headers() self.wfile.write(message.encode(&#39;utf-8&#39;)) 更新素材模型时，需要接收同事传来的新增图像数据，是以json格式传来的，我们需要解析处理。 想到1，我们用过，直接拿过来打开 import json file_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39; json_bigdata = [] try: with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp: for line in fp.readlines(): json_data = json.loads(line) json_bigdata.append(json_data) print(json_bigdata) print(len(json_bigdata)) except: print(&#39;open fail&#39;) 结果：json数据读取出来了，json数据长度为1json数据格式 &#123; &quot;code&quot;: 200, &quot;message&quot;: &quot;OK&quot;, &quot;data&quot;: [ &#123; &quot;id&quot;: 19635909, &quot;pic_url&quot;: &quot;https:\\/\\/pic.ibaotu.com\\/19\\/63\\/59\\/09G888piCrV3.jpg!fw700&quot;, &quot;tag_names&quot;: &quot;节日海报&quot; &#125;, &#123; &quot;id&quot;: 19640331, &quot;pic_url&quot;: &quot;https:\\/\\/pic.ibaotu.com\\/19\\/64\\/03\\/31c888piCFMx.jpg!fw700&quot;, &quot;tag_names&quot;: &quot;海报&quot; &#125;, &#123; &quot;id&quot;: 19643949, &quot;pic_url&quot;: &quot;https:\\/\\/pic.ibaotu.com\\/01\\/99\\/30\\/693888piC7XF.jpg!fw700&quot;, &quot;tag_names&quot;: &quot;摄影图&quot; &#125; ] &#125; 接下来我们获取每个key-value的值，来进行处理。所有数据都在一行，它读一行，就把所有数据都读出来了。json_data就是所有数据。我们用print(json_data[“message”])来看看能不能获得想要的值 file_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39; json_bigdata = [] try: with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp: for line in fp.readlines(): json_data = json.loads(line) print(json_data[&quot;message&quot;]) json_bigdata.append(json_data) # print(json_bigdata) # print(len(json_bigdata)) except: print(&#39;open fail&#39;) 运行结果是理想的 OK 接下来把message换成data，看看情况 file_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39; json_bigdata = [] try: with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp: for line in fp.readlines(): json_data = json.loads(line) print(len(json_data[&quot;data&quot;])) json_bigdata.append(json_data) # print(json_bigdata) # print(len(json_bigdata)) except: print(&#39;open fail&#39;) 结果 778数据一眼看下来，确实很多，应该是获取到了data的值，下面我们需要遍历data来得到每个具体的id，url，类型，把他们下载下来。 file_path = &#39;D:/work/search_image/vgg_picspic/update/download.json&#39; json_bigdata = [] try: with open(file_path, &#39;r&#39;, encoding=&#39;utf8&#39;) as fp: for line in fp.readlines(): json_data = json.loads(line) for i in range(len(json_data[&quot;data&quot;])): print(json_data[&quot;data&quot;][i]) json_bigdata.append(json_data) # print(json_bigdata) # print(len(json_bigdata)) except: print(&#39;open fail&#39;) 运行结果 {‘id’: 19645448, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/46/15n888piCJF9.jpg!fw700&#39;, ‘tag_names’:‘摄影图’}{‘id’: 19645623, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/48/24V888piC43a.jpg!fw700&#39;, ‘tag_names’:‘摄影图’}{‘id’: 19645624, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/48/23Z888piCb6y.jpg!fw700&#39;, ‘tag_names’:‘摄影图’}{‘id’: 19645634, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/48/40U888piCHSv.jpg!fw700&#39;, ‘tag_names’:‘摄影图’}{‘id’: 19645663, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/48/73t888piCGVY.jpg!fw700&#39;, ‘tag_names’:‘节日海报’}{‘id’: 19645667, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/48/71p888piCiK7.jpg!fw700&#39;, ‘tag_names’:‘节日海报’}{‘id’: 19645679, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/48/67J888piCrMX.jpg!fw700&#39;, ‘tag_names’:‘节日海报’}{‘id’: 19645719, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/49/28t888piCkgI.jpg!fw700&#39;, ‘tag_names’:‘节日海报’}{‘id’: 19645730, ‘pic_url’: ‘https://pic.ibaotu.com/01/99/49/39g888piCxQI.jpg!fw700&#39;, ‘tag_names’:‘节日海报’} 这个是我们想要的。下面就是得到url，按照分类下载到本地不同的文件夹，以id命名。 print(json_data[“data”][i][‘id’])print(json_data[“data”][i][‘pic_url’])print(json_data[“data”][i][‘tag_names’]) 通过url把图像下载下来 import requests url = &quot;https://pic.ibaotu.com/01/99/49/28t888piCkgI.jpg!fw700&quot; try: r = requests.get(url) #print(len(r.content)) #if len(r.content) &gt; 20000: with open(&#39;poster/&#39; + str(file[&#39;id&#39;][i]) + &#39;.jpg&#39;, &#39;wb&#39;) as code: code.write(r.content) except: num = num + 1 print(url, num) with open(&#39;url_false.txt&#39;, &#39;w+&#39;) as f: f.write(url + &#39;\\r\\n&#39;) 接下来就是进行一些图像预处理了。","categories":[{"name":"Python使用","slug":"Python使用","permalink":"http://xiaohongzhong.top/categories/Python%E4%BD%BF%E7%94%A8/"}],"tags":[{"name":"python使用","slug":"python使用","permalink":"http://xiaohongzhong.top/tags/python%E4%BD%BF%E7%94%A8/"}]},{"title":"贝叶斯算法的简单记录","slug":"贝叶斯算法的简单记录","date":"2020-12-10T10:03:38.000Z","updated":"2020-12-14T14:52:11.144Z","comments":true,"path":"2020/12/10/bei-xie-si-suan-fa-de-jian-dan-ji-lu/","link":"","permalink":"http://xiaohongzhong.top/2020/12/10/bei-xie-si-suan-fa-de-jian-dan-ji-lu/","excerpt":"","text":"","categories":[{"name":"算法","slug":"算法","permalink":"http://xiaohongzhong.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://xiaohongzhong.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"网络VGG的简单记录","slug":"网络VGG的简单记录","date":"2020-12-10T01:51:06.000Z","updated":"2020-12-10T04:16:54.434Z","comments":true,"path":"2020/12/10/wang-luo-vgg-de-jian-dan-ji-lu/","link":"","permalink":"http://xiaohongzhong.top/2020/12/10/wang-luo-vgg-de-jian-dan-ji-lu/","excerpt":"","text":"VGG 以第一处卷积为例VGG19 卷积层默认的stride是(1, 1)填充方式是same，说明输入的大小和输出的大小一样，都是224卷积核越大，计算量暴增，不利于模型深度的增加，计算性能也会降低。以第一处池化为例MaxPooling2D的padding默认是valid输出大小= (224 - (pool_size=2) + 2 * (p=0)) / (stride=2) + 1 = (224 - 2 + 0)/2 + 1 = 112 keras下的vgg19代码 # -*- coding: utf-8 -*- &quot;&quot;&quot;VGG19 model for Keras. # Reference - [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) &quot;&quot;&quot; from __future__ import absolute_import from __future__ import division from __future__ import print_function import os import warnings from ..models import Model from ..layers import Flatten from ..layers import Dense from ..layers import Input from ..layers import Conv2D from ..layers import MaxPooling2D from ..layers import GlobalAveragePooling2D from ..layers import GlobalMaxPooling2D from ..engine.topology import get_source_inputs from ..utils import layer_utils from ..utils.data_utils import get_file from .. import backend as K from .imagenet_utils import decode_predictions from .imagenet_utils import preprocess_input from .imagenet_utils import _obtain_input_shape WEIGHTS_PATH = &#39;https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5&#39; WEIGHTS_PATH_NO_TOP = &#39;https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5&#39; def VGG19(include_top=True, weights=&#39;imagenet&#39;, input_tensor=None, input_shape=None, pooling=None, classes=1000): if not (weights in &#123;&#39;imagenet&#39;, None&#125; or os.path.exists(weights)): raise ValueError(&#39;The `weights` argument should be either &#39; &#39;`None` (random initialization), `imagenet` &#39; &#39;(pre-training on ImageNet), &#39; &#39;or the path to the weights file to be loaded.&#39;) if weights == &#39;imagenet&#39; and include_top and classes != 1000: raise ValueError(&#39;If using `weights` as imagenet with `include_top`&#39; &#39; as true, `classes` should be 1000&#39;) # Determine proper input shape input_shape = _obtain_input_shape(input_shape, default_size=224, min_size=48, data_format=K.image_data_format(), require_flatten=include_top, weights=weights) if input_tensor is None: img_input = Input(shape=input_shape) else: if not K.is_keras_tensor(input_tensor): img_input = Input(tensor=input_tensor, shape=input_shape) else: img_input = input_tensor # Block 1 x = Conv2D(64, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block1_conv1&#39;)(img_input) x = Conv2D(64, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block1_conv2&#39;)(x) x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block1_pool&#39;)(x) # Block 2 x = Conv2D(128, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block2_conv1&#39;)(x) x = Conv2D(128, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block2_conv2&#39;)(x) x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block2_pool&#39;)(x) # Block 3 x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv1&#39;)(x) x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv2&#39;)(x) x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv3&#39;)(x) x = Conv2D(256, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block3_conv4&#39;)(x) x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block3_pool&#39;)(x) # Block 4 x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv1&#39;)(x) x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv2&#39;)(x) x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv3&#39;)(x) x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block4_conv4&#39;)(x) x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block4_pool&#39;)(x) # Block 5 x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv1&#39;)(x) x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv2&#39;)(x) x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv3&#39;)(x) x = Conv2D(512, (3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;, name=&#39;block5_conv4&#39;)(x) x = MaxPooling2D((2, 2), strides=(2, 2), name=&#39;block5_pool&#39;)(x) if include_top: # Classification block x = Flatten(name=&#39;flatten&#39;)(x) x = Dense(4096, activation=&#39;relu&#39;, name=&#39;fc1&#39;)(x) x = Dense(4096, activation=&#39;relu&#39;, name=&#39;fc2&#39;)(x) x = Dense(classes, activation=&#39;softmax&#39;, name=&#39;predictions&#39;)(x) else: if pooling == &#39;avg&#39;: x = GlobalAveragePooling2D()(x) elif pooling == &#39;max&#39;: x = GlobalMaxPooling2D()(x) # Ensure that the model takes into account # any potential predecessors of `input_tensor`. if input_tensor is not None: inputs = get_source_inputs(input_tensor) else: inputs = img_input # Create model. model = Model(inputs, x, name=&#39;vgg19&#39;) # load weights if weights == &#39;imagenet&#39;: if include_top: weights_path = get_file(&#39;vgg19_weights_tf_dim_ordering_tf_kernels.h5&#39;, WEIGHTS_PATH, cache_subdir=&#39;models&#39;, file_hash=&#39;cbe5617147190e668d6c5d5026f83318&#39;) else: weights_path = get_file(&#39;vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5&#39;, WEIGHTS_PATH_NO_TOP, cache_subdir=&#39;models&#39;, file_hash=&#39;253f8cb515780f3b799900260a226db6&#39;) model.load_weights(weights_path) if K.backend() == &#39;theano&#39;: layer_utils.convert_all_kernels_in_model(model) if K.image_data_format() == &#39;channels_first&#39;: if include_top: maxpool = model.get_layer(name=&#39;block5_pool&#39;) shape = maxpool.output_shape[1:] dense = model.get_layer(name=&#39;fc1&#39;) layer_utils.convert_dense_weights_data_format(dense, shape, &#39;channels_first&#39;) if K.backend() == &#39;tensorflow&#39;: warnings.warn(&#39;You are using the TensorFlow backend, yet you &#39; &#39;are using the Theano &#39; &#39;image data format convention &#39; &#39;(`image_data_format=&quot;channels_first&quot;`). &#39; &#39;For best performance, set &#39; &#39;`image_data_format=&quot;channels_last&quot;` in &#39; &#39;your Keras config &#39; &#39;at ~/.keras/keras.json.&#39;) elif weights is not None: model.load_weights(weights) return model 3x3是最小的能够捕获像素八邻域信息的尺寸。 两个3x3的堆叠卷基层的有限感受野是5x5；三个3x3的堆叠卷基层的感受野是7x7，故可以通过小尺寸卷积层的堆叠替代大尺寸卷积层，并且感受野大小不变。 多个3x3的卷基层比一个大尺寸filter卷基层有更多的非线性（更多层的非线性函数），使得判决函数更加具有判决性。 多个3x3的卷积层比一个大尺寸的filter有更少的参数，假设卷基层的输入和输出的特征图大小相同为C，那么三个3x3的卷积层参数个数3x（3x3xCxC）=27C2；一个7x7的卷积层参数为49C2；所以可以把三个3x3的filter看成是一个7x7filter的分解（中间层有非线性的分解, 并且起到隐式正则化的作用。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"经典神经网络","slug":"经典神经网络","permalink":"http://xiaohongzhong.top/tags/%E7%BB%8F%E5%85%B8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"author":"xiao"},{"title":"图像分类-自己的数据集-Pytorch","slug":"图像分类-自己的数据集-Pytorch","date":"2020-12-08T09:57:29.000Z","updated":"2020-12-09T03:26:33.903Z","comments":true,"path":"2020/12/08/tu-xiang-fen-lei-zi-ji-de-shu-ju-ji-pytorch/","link":"","permalink":"http://xiaohongzhong.top/2020/12/08/tu-xiang-fen-lei-zi-ji-de-shu-ju-ji-pytorch/","excerpt":"","text":"数据集整理划分train_transforms = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) train_datasets = datasets.ImageFolder(&#39;dataset/logos_v2&#39;, transform=train_transforms) train_size = int(0.8 * len(train_datasets)) test_size = len(train_datasets) - int(0.8 * len(train_datasets)) train_dataset, test_dataset = torch.utils.data.random_split(train_datasets, [train_size, test_size]) train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0) test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0) 训练可视化一开始先定义 from visdom import Visdom # 将窗口类实例化 viz = Visdom() viz.line([[0., 0.]], [0], win=&#39;train&#39;, opts=dict(title=&#39;train&#39;, legend=[&#39;train_loss&#39;, &#39;train_acc&#39;])) viz.line([[0., 0.]], [0], win=&#39;test&#39;, opts=dict(title=&#39;test&#39;, legend=[&#39;test_loss&#39;, &#39;test_acc&#39;])) 后面再记录loss和acc的变化 # 更新窗口图像 viz.line([[running_loss / len(train_dataset), train_acc / len(train_dataset)]], [epoch], win=&#39;train&#39;, update=&#39;append&#39;) model.train()和model.eval()eval()时，pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。不然的话，一旦test的batch_size过小，很容易就会被BN层导致生成图片颜色失真极大。 完整代码import torch from torchvision import models, datasets, transforms import matplotlib.pyplot as plt import torch.nn as nn import torch.optim as optim import torch.nn.functional as F from visdom import Visdom # 将窗口类实例化 viz = Visdom() viz.line([[0., 0.]], [0], win=&#39;train&#39;, opts=dict(title=&#39;train&#39;, legend=[&#39;train_loss&#39;, &#39;train_acc&#39;])) viz.line([[0., 0.]], [0], win=&#39;test&#39;, opts=dict(title=&#39;test&#39;, legend=[&#39;test_loss&#39;, &#39;test_acc&#39;])) device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) train_transforms = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) train_datasets = datasets.ImageFolder(&#39;dataset/logos_v2&#39;, transform=train_transforms) train_size = int(0.8 * len(train_datasets)) test_size = len(train_datasets) - int(0.8 * len(train_datasets)) train_dataset, test_dataset = torch.utils.data.random_split(train_datasets, [train_size, test_size]) train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0) test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0) classes = (&#39;bear&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;chicken&#39;, &#39;coffee&#39;, &#39;dog&#39;, &#39;duck&#39;, &#39;fish&#39;, &#39;flower&#39;, &#39;tree&#39;) net = models.vgg19(pretrained=True) net.to(device) criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 训练网络 for epoch in range(10): net.train() running_loss = 0.0 train_acc = 0.0 for i, data in enumerate(train_dataloader, 0): inputs, labels = data inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() # 经过测试，pred1 = torch.max(outputs, 1)[1]是和_, pred = torch.max(outputs.data, 1) 的pred相等的！！！ #pred1 = torch.max(outputs, 1)[1] _, pred = torch.max(outputs.data, 1) train_correct = (pred == labels).sum() train_acc += train_correct.item() if i == len(train_dataloader) - 1: print(&#39;Training [%d, %5d] loss: %.3f acc: %.3f&#39; % (epoch + 1, i + 1, running_loss / len(train_dataset), train_acc / len(train_dataset))) # 更新窗口图像 viz.line([[running_loss / len(train_dataset), train_acc / len(train_dataset)]], [epoch], win=&#39;train&#39;, update=&#39;append&#39;) running_loss = 0.0 # 验证集 net.eval() eval_loss = 0.0 eval_acc = 0.0 for i, data in enumerate(test_dataloader, 0): inputs, labels = data inputs, labels = inputs.to(device), labels.to(device) outputs = net(inputs) loss = criterion(outputs, labels) eval_loss += loss.item() _, pred = torch.max(outputs.data, 1) num_correct = (pred == labels).sum() eval_acc += num_correct.item() if i == len(test_dataloader) - 1: print(&#39;Evaluating [%d, %5d] loss: %.3f acc: %.3f&#39; % (epoch + 1, i + 1, eval_loss / len(test_dataset), eval_acc / len(test_dataset))) viz.line([[eval_loss / len(test_dataset), eval_acc / len(test_dataset)]], [epoch], win=&#39;test&#39;, update=&#39;append&#39;) eval_loss = 0.0 torch.save(net.state_dict(), &#39;model/logos_v2.pkl&#39;) print(&#39;Finished Training&#39;) # 预测 dataiter = iter(test_dataloader) images, labels = dataiter.next() #imshow(torchvision.utils.make_grid(images)) print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) images, labels = images.to(device), labels.to(device) #outputs = net(images) net.load_state_dict(torch.load(&#39;model/logos_v2.pkl&#39;)) outputs = net(images) _, predicted = torch.max(outputs, 1) print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4))) # 整个数据集预测 correct = 0 total = 0 with torch.no_grad(): for data in test_dataloader: images, labels = data images, labels = images.to(device), labels.to(device) #outputs = net(images) net.load_state_dict(torch.load(&#39;model/logos_v2.pkl&#39;)) outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct / total))","categories":[{"name":"图像分类","slug":"图像分类","permalink":"http://xiaohongzhong.top/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://xiaohongzhong.top/tags/Pytorch/"}]},{"title":"深度学习之计算机视觉概念","slug":"深度学习之计算机视觉概念","date":"2020-12-08T03:06:19.000Z","updated":"2020-12-08T04:15:39.017Z","comments":true,"path":"2020/12/08/shen-du-xue-xi-zhi-ji-suan-ji-shi-jue-gai-nian/","link":"","permalink":"http://xiaohongzhong.top/2020/12/08/shen-du-xue-xi-zhi-ji-suan-ji-shi-jue-gai-nian/","excerpt":"","text":"卷积填充 池化它们会降低特征平面和卷积层输出的大小池化提供两种不同的功能：一个是减少要处理的数据大小，一个是强制算法不关注图像位置的微小变化 激活函数ReLU","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"图像分类-CIFAR10-Pytorch","slug":"图像分类-CIFAR10-Pytorch","date":"2020-12-04T02:13:46.000Z","updated":"2020-12-08T04:13:43.393Z","comments":true,"path":"2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/","link":"","permalink":"http://xiaohongzhong.top/2020/12/04/tu-xiang-fen-lei-cifar10-pytorch/","excerpt":"","text":"想要使用pytorch，就从最基础的图像分类，也是最熟悉的图像分类开始。 这是官网中文中的代码 http://pytorch123.com/SecondSection/training_a_classifier/ 数据集如果直接从源代码下载CIFAR10数据集，本来就只有160M，结果下载一天也没下载好，下载太慢。建议从网上寻找数据集。 下载完之后，需要修改源码内容。打开我在anaconda下安装torch的虚拟环境，找到torchvision的包，在datasets文件夹下面有个cifar.py C:\\Users\\DELL\\Anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\datasets\\cifar.py class CIFAR10(VisionDataset): &quot;&quot;&quot;`CIFAR10 &lt;https://www.cs.toronto.edu/~kriz/cifar.html&gt;`_ Dataset. Args: root (string): Root directory of dataset where directory ``cifar-10-batches-py`` exists or will be saved to if download is set to True. train (bool, optional): If True, creates dataset from training set, otherwise creates from test set. transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed version. E.g, ``transforms.RandomCrop`` target_transform (callable, optional): A function/transform that takes in the target and transforms it. download (bool, optional): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. &quot;&quot;&quot; base_folder = &#39;cifar-10-batches-py&#39; #url = &quot;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&quot; url = &quot;file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz&quot; filename = &quot;cifar-10-python.tar.gz&quot; tgz_md5 = &#39;c58f30108f718f92721af3b95e74349a&#39; train_list = [ [&#39;data_batch_1&#39;, &#39;c99cafc152244af753f735de768cd75f&#39;], [&#39;data_batch_2&#39;, &#39;d4bba439e000b95fd0a9bffe97cbabec&#39;], [&#39;data_batch_3&#39;, &#39;54ebc095f3ab1f0389bbae665268c751&#39;], [&#39;data_batch_4&#39;, &#39;634d18415352ddfa80567beed471001a&#39;], [&#39;data_batch_5&#39;, &#39;482c414d41f54cd18b22e5b47cb7c3cb&#39;], ] 修改url，把url变成file:///D:/work/search_image/torch/dataset/cifar-10-python.tar.gz（这个是我下载的cifar10放置的位置）之后运行 import torchvision as tv import torchvision.transforms as transforms from torchvision.transforms import ToPILImage import torch.nn as nn import torch.nn.functional as F import torch show = ToPILImage() # 可以把tensor转成Image，方便可视化 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) trainset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = tv.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;) (data, label) = trainset[100] print(classes[label]) print(len(trainset)) print(len(testset)) 输出： Files already downloaded and verified Files already downloaded and verified ship 50000 10000 创建网络class Net_my(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(x.size()[0], -1) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x 本来报错： class Net_my(nn.modules):TypeError: module.init() takes at most 2 arguments (3 given) nn.modules -&gt; nn.Module就ok了。 训练报错 BrokenPipeError: [Errno 32] Broken pipe 好像是win10的多线程导致的，需要避免windows使用多线程。把torch.utils.data.DataLoader()函数时的 num_workers 参数改成0。 RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same 要么都是cpu，要么都是gpu，需要统一 net.cuda()device = torch.device(“cuda:0” if torch.cuda.is_available() else “cpu”)#网络和输入的数据都需要转成gpu或者cpu。 可以训练 # net = Net() # net.cuda() # from torch import optim # criterion = nn.CrossEntropyLoss() # optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) # # torch.set_num_threads(8) # for epoch in range(10): # running_loss = 0.0 # total = 0 # correct = 0 # for i, data in enumerate(trainloader, 0): # inputs, labels = data # inputs, labels = inputs.to(device),labels.to(device) # # optimizer.zero_grad() # outputs = net(inputs) # loss = criterion(outputs, labels) # loss.backward() # # optimizer.step() # # running_loss += loss.item() # # if i % 2000 == 1999: # print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch+1, i+1, running_loss / 2000)) # running_loss = 0.0 # _, predicted = torch.max(outputs, 1) # total += labels.size(0) # correct += (predicted == labels).sum().item() # print(&#39;accuracy of the network on the %d train images: %.3f %%&#39; % (total, 100.0 * correct / total)) # total = 0 # correct = 0 # # print(&#39;Finished Training&#39;) 使用预训练模型来图像分类import torchvision as tv import torchvision.transforms as transforms from torchvision.transforms import ToPILImage import torch.nn as nn import torch.nn.functional as F import torch from torchvision import models from PIL import Image alexnet = models.alexnet(pretrained=True) print(alexnet) img = Image.open(&#39;1.jpg&#39;) transform = transforms.Compose([ #[1] transforms.Resize(256), #[2] transforms.CenterCrop(224), #[3] transforms.ToTensor(), #[4] transforms.Normalize( #[5] mean=[0.485, 0.456, 0.406], #[6] std=[0.229, 0.224, 0.225] #[7] )]) img_t = transform(img) batch_t = torch.unsqueeze(img_t, 0) alexnet.eval() out = alexnet(batch_t) with open(&#39;imagenet_classes.txt&#39;) as f: classes = [line.strip() for line in f.readlines()] _, indices = torch.sort(out, descending=True) percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100 [print(classes[idx], percentage[idx].item()) for idx in indices[0][:5]] 输出 655: &#39;miniskirt, mini&#39;, 10.492936134338379 765: &#39;rocking chair, rocker&#39;, 4.194277286529541 545: &#39;electric fan, blower&#39;, 4.150004863739014 411: &#39;apron&#39;, 2.946284532546997 589: &#39;hand blower, blow dryer, blow drier, hair dryer, hair drier&#39;, 2.749168872833252 完整代码import torch import torchvision import torchvision.transforms as transforms device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) # 使用torchvision加载并且归一化CIFAR10的训练和测试数据集 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) trainset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0) testset = torchvision.datasets.CIFAR10(root=&#39;D:/work/search_image/torch/dataset/&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0) classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;) # 显示一批图像 import matplotlib.pyplot as plt import numpy as np def imshow(img): img = img / 2 + 0.5 npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) plt.show() dataiter = iter(trainloader) images, labels = dataiter.next() #imshow(torchvision.utils.make_grid(images)) print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) # 定义一个卷积神经网络 import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() net.to(device) # 定义一个损失函数和优化器 让我们使用分类交叉熵Cross-Entropy 作损失函数，动量SGD做优化器。 import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 训练网络 for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 1562 == 1555: print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 torch.save(net.state_dict(), &#39;model/cifar10.pkl&#39;) print(&#39;Finished Training&#39;) # 预测 dataiter = iter(testloader) images, labels = dataiter.next() #imshow(torchvision.utils.make_grid(images)) print(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4))) images, labels = images.to(device), labels.to(device) #outputs = net(images) net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;)) outputs = net(images) _, predicted = torch.max(outputs, 1) print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4))) # 整个数据集预测 correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data images, labels = images.to(device), labels.to(device) #outputs = net(images) net.load_state_dict(torch.load(&#39;model/cifar10.pkl&#39;)) outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct / total)) # 最后测试准确率在53%左右","categories":[{"name":"图像分类","slug":"图像分类","permalink":"http://xiaohongzhong.top/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://xiaohongzhong.top/tags/Pytorch/"}]},{"title":"跑通图像压缩算法SReC","slug":"SReC","date":"2020-12-03T06:41:52.000Z","updated":"2020-12-09T09:11:49.959Z","comments":true,"path":"2020/12/03/srec/","link":"","permalink":"http://xiaohongzhong.top/2020/12/03/srec/","excerpt":"","text":"环境：win10 源码位置：https://github.com/caoscott/SReC 下载源码git clone &#103;&#105;&#x74;&#x40;&#103;&#105;&#x74;&#104;&#x75;&#x62;&#x2e;&#x63;&#x6f;&#109;:caoscott/SReC.git 搭建环境，使用的是没有nvidia-docker的方法我是已经装了torch1.5.0 + torchvision0.6.0 + gpu的环境，接下来 pip install -r requirements.txt 安装gcc，参考的是这个大佬的文章https://blog.csdn.net/qilimi1053620912/article/details/88573017在windows10上安装gcc。 运行COMPILE_CUDA=force python3 setup.py install，报错 error: command ‘C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX86\\x64\\cl.exe’ failed with exit status 2 搞不定啊","categories":[{"name":"跑过的算法","slug":"跑过的算法","permalink":"http://xiaohongzhong.top/categories/%E8%B7%91%E8%BF%87%E7%9A%84%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"图像压缩","slug":"图像压缩","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/"},{"name":"图像处理","slug":"图像处理","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"supervisor + scrapy + python","slug":"supervisor-scrapy-python","date":"2020-11-26T06:42:57.000Z","updated":"2020-12-08T04:15:20.963Z","comments":true,"path":"2020/11/26/supervisor-scrapy-python/","link":"","permalink":"http://xiaohongzhong.top/2020/11/26/supervisor-scrapy-python/","excerpt":"","text":"在ubuntu16.04下，首先爬取新浪微博的话题和关键词，然后会返回爬到的微博用户id，bid，和图像url。之后再把这些图像送到深度学习所做的图像侵权检测系统，判断是否侵权我们的素材，返回相关的信息。 1.图像侵权检测 2.python 开启http服务 3.scrapy 爬取新浪微博 4.supervisor 进程管理 其实123慢慢调好了，这周调的最多的是怎么把1234放在一起，碰到了相当多的问题。 开启supervisor 执行的命令可以是虚拟环境的命令，需要加上路径比如 [program:ibaotu-image-match]command=/usr/local/data/anaconda3/envs/snakes/bin/python /usr/local/data/www/weibo_search_master/http_server_GET.pydirectory=/usr/local/data/www/weibo_search_masterautostart=trueautorestart=truestdout_logfile=/usr/local/data/www/log/out.logstderr_logfile=/usr/local/data/www/log/err.log 执行命令的时候就知道是执行哪里的python了 还可以web查看管理supervisor [inet_http_server] ; inet (TCP) server disabled by defaultport=*:9001 ; (ip_address:port specifier, *:port for all iface);username=admin ; (default is no username (open server));password=admin ; (default is no password (open server)) supervisor命令查看状态supervisorctl status更新supervisorctl update重置supervisorctl reload结束supervisorctl stop all开始supervisorctl start all更新配置supervisord -c /etc/supervisord/supervisord.conf 遇到的报错 unix:///var/run/supervisor.sock no such file 1.sudo touch /var/run/supervisor.sock 2.sudo chmod 777 /var/run/supervisor.sock 3.sudo service supervisor restart unix:///var/run/supervisor/supervisor.sock refused connection supervisord -c /etc/supervisord/supervisord.conf启动supervisord并使用配置 The ‘supervisor==3.2.0’ distribution was not found and is required by the application 如果默认的python是python2,应该不会报错。如果是python3，就要修改和terminator一样也是python版本引起的，编辑/usr/bin/supervisord将#!/usr/bin/python修改为#!/usr/bin/python2即可貌似启动supervisor 只能用python2 supervisord不能正常地话，查看它的log supervisorctl tail ibaotu-image-match stderr supervisorctl 启动起来，一直在报错重启， OSError: [Errno 98] Address already in use 1.netstat -tunlpkill -9 6153这个是每次都要这样，有点烦2.find / -name supervisor.sockunlink /name/supervisor.sock root@ibaotu-algo:/usr/bin# scrapyTraceback (most recent call last): File “/usr/local/bin/scrapy”, line 7, in from scrapy.cmdline import execute File “/usr/local/lib/python3.5/dist-packages/scrapy/init.py”, line 12, in from scrapy.spiders import Spider File “/usr/local/lib/python3.5/dist-packages/scrapy/spiders/init.py”, line 22 name: Optional[str] = None ^SyntaxError: invalid syntax 在虚拟环境是好的，但是放在一起跑就出问题了。我研究了好久，才发现还是命令路径的问题。在终端输入scrapy，虚拟环境是ok的，在普通的就报错。两个scrapy版本是一样的，只不过虚拟环境的python是3.6.5，普通的python是3.5.2，不知道是不是和这个有关。把scrapy改成/usr/local/data/anaconda3/envs/snakes/bin/scrapy scrapy是命令行，怎么在代码里面添加？ #cmdline.execute([&quot;scrapy&quot;, &quot;crawl&quot;, &quot;search&quot;, &quot;-a&quot;, &quot;start_date=%s&quot;%(start_date), &quot;-a&quot;, &quot;end_date=%s&quot;%(end_date), &quot;-a&quot;, &quot;keyword_list=%s&quot;%(keyword)]) cmd = &quot;/usr/local/data/anaconda3/envs/snakes/bin/scrapy crawl search -a &quot; + &quot;start_date=%s&quot;%(start_date) + &quot; -a &quot; + &quot;end_date=%s&quot;%(end_date) + &quot; -a &quot; + &quot;keyword_list=%s&quot;%(keyword) os.system(cmd) 开启的http服务，客户请求爬虫，怎么把数据返回？ 一开始的想法是能不能搞个全局变量。怎么搞也搞不过去，python跨文件的全局变量，后面知道scrapy是新开的进程，数据根本到不了。后面把数据存到csv或者json文件，爬完再读取，再返回。 no module named … 因为路径的问题，也搞了好久，明明都添加了，还是报错，sys.path.append()最后因为没有使用到全局变量，这个报错也就不了了之了。 遍历字典，写入csv，一个数据固定的写入一行 writer.writerow([item[‘weibo’][key] for key in item[‘weibo’].keys() if key == ‘id’ or key == ‘bid’ or key == ‘pics’]) 是csv转成json，还是直接爬取pipeline到json 我选择了后者，爬取了json格式的文件下来，包括id，bid，picurl组成的json格式的数据。一开始json格式还写不进去，应该是格式问题，我弄了data格式，之后ok了。 with codecs.open(jsonfile_path, &#39;a+&#39;) as f: data = &#123; &#39;id&#39;: item[&#39;weibo&#39;][&#39;user_id&#39;], &#39;bid&#39;: item[&#39;weibo&#39;][&#39;bid&#39;], &#39;screen_name&#39;: item[&#39;weibo&#39;][&#39;screen_name&#39;], &#39;pics&#39;: item[&#39;weibo&#39;][&#39;pics&#39;] &#125; lines = json.dumps(data, ensure_ascii=False) f.write(lines + &quot;\\n&quot;) 然后也出现supervisor一直重启的问题 因为配置中restart:默认为true，然后一直有htpp进程开着，报错OSError: [Errno 98] Address already in use；还有个原因就是原来的程序不是死循环，一会运行结束，又重启了。 最后这个1234基本就能愉快地在一起玩耍了。","categories":[{"name":"项目经验","slug":"项目经验","permalink":"http://xiaohongzhong.top/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://xiaohongzhong.top/tags/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"http://xiaohongzhong.top/tags/python/"}]},{"title":"Conda的使用","slug":"Conda的使用","date":"2020-11-23T13:00:20.000Z","updated":"2020-12-08T04:12:26.119Z","comments":true,"path":"2020/11/23/conda-de-shi-yong/","link":"","permalink":"http://xiaohongzhong.top/2020/11/23/conda-de-shi-yong/","excerpt":"","text":"安装Anaconda首先需要安装anaconda，在不同的电脑上下载使用很多次了，还是挺方便的。正好开通了博客，就记录下conda的使用。 conda 创建虚拟环境anaconda安装成功之后，如果不成功，网上很多安装的博客可以查看。应该有conda命令了。 conda -V 返回conda 4.7.12 1.创建虚拟环境命令：conda create --name pytorch python=3.6.5 安装总是失败 Collecting package metadata (current_repodata.json): ...working... done Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): ...working... 我添加了conda换源，可是还是不行 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes 修改命令conda create --name pytorch python=3.6 $ conda create -n tensorflow python=3.6.5 Collecting package metadata (repodata.json): done Solving environment: done ==&gt; WARNING: A newer version of conda exists. &lt;== current version: 4.8.3 latest version: 4.9.2 Please update conda by running $ conda update -n base -c defaults conda ## Package Plan ## environment location: C:\\Users\\DELL\\Anaconda3\\envs\\tensorflow added / updated specs: - python=3.6.5 The following packages will be downloaded: package | build ---------------------------|----------------- certifi-2020.11.8 | py36haa95532_0 151 KB pip-20.2.4 | py36haa95532_0 2.1 MB python-3.6.5 | h0c2934d_0 21.6 MB setuptools-50.3.1 | py36haa95532_1 939 KB vc-14.1 | h0510ff6_4 6 KB vs2015_runtime-14.16.27012 | hf0eaf9b_3 2.4 MB wincertstore-0.2 | py36h7fe50ca_0 13 KB ------------------------------------------------------------ Total: 27.2 MB The following NEW packages will be INSTALLED: done # # To activate this environment, use # # $ conda activate tensorflow # # To deactivate an active environment, use # # $ conda deactivate 2.安装成功之后，可以查看确认下conda env list conda 进入虚拟环境conda activate tensorflow或者source activate tensorflow conda 退出虚拟环境conda deactivate或者试试source deactivate没有退出，就多输入几次命令 conda 添加镜像conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config –add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/#显示安装的镜像conda config –set show_channel_urls yes#已添加的channel在哪里查看.condarc conda 删除虚拟环境conda remove -n tensorflow –all conda remove -n tensorflow --all Remove all packages in environment C:\\Users\\DELL\\Anaconda3\\envs\\tensorflow: ## Package Plan ## environment location: C:\\Users\\DELL\\Anaconda3\\envs\\tensorflow The following packages will be REMOVED: certifi-2020.11.8-py36haa95532_0 pip-20.2.4-py36haa95532_0 python-3.6.5-h0c2934d_0 setuptools-50.3.1-py36haa95532_1 vc-14.1-h0510ff6_4 vs2015_runtime-14.16.27012-hf0eaf9b_3 wheel-0.35.1-pyhd3eb1b0_0 wincertstore-0.2-py36h7fe50ca_0 Proceed ([y]/n)? y Preparing transaction: done Verifying transaction: done Executing transaction: done 我正常用的就是这些命令，记录一下。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://xiaohongzhong.top/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://xiaohongzhong.top/tags/anaconda/"}]},{"title":"开发工具","slug":"开发工具","date":"2020-11-19T06:28:49.000Z","updated":"2020-12-08T04:13:10.214Z","comments":true,"path":"2020/11/19/kai-fa-gong-ju/","link":"","permalink":"http://xiaohongzhong.top/2020/11/19/kai-fa-gong-ju/","excerpt":"","text":"这里是我日常使用的一些工具，主要是Windows上的，也有Ubuntu的。编辑器：Atom （使用体验超级好）Packages：1.Hydropen2.activate_power_mode3.atom_python_run4.atom_terminal5.autocomplete-python6.hyperclick7.ide-python8.kite # 特别好用，使用有惊喜9.minimap10.python-tools11.run-in-terminal其他很多包全是core packages，不进行列举。 远程连接传输工具：Xshell Winscp PuttyCoding：Pycharm Anaconda Visual-Studio Source-Insight数据库：HeidiSQL查看神经网络的结构：NetronCuda：v10.0Cudnn：v7.6.5查看windows文件：listary","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://xiaohongzhong.top/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://xiaohongzhong.top/tags/%E5%B7%A5%E5%85%B7/"}]}],"categories":[{"name":"跑过的算法","slug":"跑过的算法","permalink":"http://xiaohongzhong.top/categories/%E8%B7%91%E8%BF%87%E7%9A%84%E7%AE%97%E6%B3%95/"},{"name":"Python使用","slug":"Python使用","permalink":"http://xiaohongzhong.top/categories/Python%E4%BD%BF%E7%94%A8/"},{"name":"算法","slug":"算法","permalink":"http://xiaohongzhong.top/categories/%E7%AE%97%E6%B3%95/"},{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"图像分类","slug":"图像分类","permalink":"http://xiaohongzhong.top/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"},{"name":"项目经验","slug":"项目经验","permalink":"http://xiaohongzhong.top/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C/"},{"name":"开发工具","slug":"开发工具","permalink":"http://xiaohongzhong.top/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"目标检测","slug":"目标检测","permalink":"http://xiaohongzhong.top/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"深度学习","slug":"深度学习","permalink":"http://xiaohongzhong.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"python使用","slug":"python使用","permalink":"http://xiaohongzhong.top/tags/python%E4%BD%BF%E7%94%A8/"},{"name":"算法","slug":"算法","permalink":"http://xiaohongzhong.top/tags/%E7%AE%97%E6%B3%95/"},{"name":"经典神经网络","slug":"经典神经网络","permalink":"http://xiaohongzhong.top/tags/%E7%BB%8F%E5%85%B8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"图像处理","slug":"图像处理","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://xiaohongzhong.top/tags/Pytorch/"},{"name":"图像压缩","slug":"图像压缩","permalink":"http://xiaohongzhong.top/tags/%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9/"},{"name":"爬虫","slug":"爬虫","permalink":"http://xiaohongzhong.top/tags/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"http://xiaohongzhong.top/tags/python/"},{"name":"anaconda","slug":"anaconda","permalink":"http://xiaohongzhong.top/tags/anaconda/"},{"name":"工具","slug":"工具","permalink":"http://xiaohongzhong.top/tags/%E5%B7%A5%E5%85%B7/"}]}